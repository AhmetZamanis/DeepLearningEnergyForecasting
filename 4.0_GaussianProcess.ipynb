{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bd4214-e9ea-4058-bd70-e97ab19ac65c",
   "metadata": {},
   "source": [
    "This notebook uses the GPyTorch package to apply Gaussian Process regression to the multi-step energy consumption forecasting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08149750-e8ab-40e7-bbe8-fc184e72c1be",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a418d22-4023-4f4d-93bc-8280ed0a961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gpytorch\n",
    "import torch\n",
    "\n",
    "from gpytorch.kernels import ScaleKernel, LinearKernel, PeriodicKernel, AdditiveKernel, ProductKernel\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.priors import NormalPrior\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669d2852-8794-427f-9d0a-d240d55cb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1923"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe418ee7-9e5d-44f4-9cc3-0eb0f48ba691",
   "metadata": {},
   "source": [
    "Using the torch.float32 datatype with variational inference seems to cause issues with zero values in matrix algebra. Using float64 and disabling mixed precision fixes them but slows down training quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8a6d62-f05e-4689-afde-6edd36dac68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Torch settings\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fedd871b-5f69-4cab-8583-d5a58dad00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcbe585-0804-4a60-a97e-2d3a957c0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./OutputData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20e98cf-95b1-477f-966d-83d1d5064616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_dir + \"full_data.csv\")\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], format = \"%d:%m:%Y:%H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ac72c8-f4b5-4cce-bcc3-439640f338dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop generation columns\n",
    "gen_cols = df.columns.values[2:].tolist()\n",
    "df = df.drop(gen_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1d9ff2-4bf8-41ca-a272-a601006d0932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>consumption_MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>27412.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>26324.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>24635.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>23872.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>23194.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>35090.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>33310.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52581</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>32083.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52582</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>30469.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52583</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>30029.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52584 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  consumption_MWh\n",
       "0     2018-01-01 00:00:00         27412.81\n",
       "1     2018-01-01 01:00:00         26324.39\n",
       "2     2018-01-01 02:00:00         24635.32\n",
       "3     2018-01-01 03:00:00         23872.12\n",
       "4     2018-01-01 04:00:00         23194.89\n",
       "...                   ...              ...\n",
       "52579 2023-12-31 19:00:00         35090.93\n",
       "52580 2023-12-31 20:00:00         33310.94\n",
       "52581 2023-12-31 21:00:00         32083.96\n",
       "52582 2023-12-31 22:00:00         30469.49\n",
       "52583 2023-12-31 23:00:00         30029.91\n",
       "\n",
       "[52584 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae553b-5c8b-49c7-a486-6c5185bf111e",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a92aba0-eac9-4eb3-a5f5-2bc7ebbd3c28",
   "metadata": {},
   "source": [
    "# Using the consumption lag as a predictor would require the model to be applied autoregressively for multi-horizon forecasts.\n",
    "df[\"consumption_lag2\"] = df[\"consumption_MWh\"].shift(2)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196c616-a1ce-4339-8ab7-c83406f0dd4e",
   "metadata": {},
   "source": [
    "We do not need to cyclical encode seasonal features, as we will apply periodic kernels to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aac49c4-dc2f-4768-8449-6b723c6127bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time columns\n",
    "\n",
    "# Trend\n",
    "df[\"trend\"] = df.index.values\n",
    "\n",
    "# Hour of day\n",
    "df[\"hour\"] = df.time.dt.hour + 1\n",
    "\n",
    "# Day of week\n",
    "df[\"dayofweek\"] = df.time.dt.dayofweek + 1\n",
    "\n",
    "# Month\n",
    "df[\"month\"] = df.time.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82996eeb-c9ae-4f26-92ca-752ed658a964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>consumption_MWh</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>27412.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>26324.39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>24635.32</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>23872.12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>23194.89</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>35090.93</td>\n",
       "      <td>52579</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>33310.94</td>\n",
       "      <td>52580</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52581</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>32083.96</td>\n",
       "      <td>52581</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52582</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>30469.49</td>\n",
       "      <td>52582</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52583</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>30029.91</td>\n",
       "      <td>52583</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52584 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  consumption_MWh  trend  hour  dayofweek  month\n",
       "0     2018-01-01 00:00:00         27412.81      0     1          1      1\n",
       "1     2018-01-01 01:00:00         26324.39      1     2          1      1\n",
       "2     2018-01-01 02:00:00         24635.32      2     3          1      1\n",
       "3     2018-01-01 03:00:00         23872.12      3     4          1      1\n",
       "4     2018-01-01 04:00:00         23194.89      4     5          1      1\n",
       "...                   ...              ...    ...   ...        ...    ...\n",
       "52579 2023-12-31 19:00:00         35090.93  52579    20          7     12\n",
       "52580 2023-12-31 20:00:00         33310.94  52580    21          7     12\n",
       "52581 2023-12-31 21:00:00         32083.96  52581    22          7     12\n",
       "52582 2023-12-31 22:00:00         30469.49  52582    23          7     12\n",
       "52583 2023-12-31 23:00:00         30029.91  52583    24          7     12\n",
       "\n",
       "[52584 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1cf01c5-706c-44a3-93fc-bbb5147eabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation parameters that match the sequence2sequence testing scheme\n",
    "horizon = 32 # Forecast horizon\n",
    "first_t = df[df[\"time\"] == '2022-10-18 16:00:00'].index[0] # First prediction point\n",
    "stride = 24 # Number of timesteps between each prediction point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d18ff6f2-7ef9-4bde-9082-b24a1b1d2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features & target\n",
    "X = df.drop([\"time\", \"consumption_MWh\",], axis = 1).values\n",
    "y = df[\"consumption_MWh\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f6d5116-dcf6-4035-a797-6ca7152addfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test = X[:first_t, :], X[first_t:, :]\n",
    "y_train, y_test = y[:first_t], y[first_t:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d6ebe0-cf5f-4839-a464-f410efd0259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature & target scaling (0-1), tensor conversion\n",
    "scaler = MinMaxScaler()\n",
    "X_train = torch.tensor(scaler.fit_transform(X_train))\n",
    "X_test = torch.tensor(scaler.transform(X_test))\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "y_train = torch.tensor(scaler_target.fit_transform(y_train.reshape(-1, 1))).squeeze(-1)\n",
    "y_test = torch.tensor(scaler_target.transform(y_test.reshape(-1, 1))).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11356245-6bc8-4084-addc-71ecf6038146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset training data to fit into memory\n",
    "train_size = int(24 * 365 * 1)\n",
    "X_train = X_train[-train_size:, :]\n",
    "y_train = y_train[-train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce54873e-f8b5-4586-9f2e-22ebee567fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8760, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85695f2d-70d5-4c31-a16e-61dddb183f55",
   "metadata": {},
   "source": [
    "## Model & wrapper definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727d65f-006f-418b-bcb0-964639f8cd1a",
   "metadata": {},
   "source": [
    "Summary of training strategies tried:\n",
    "- ExactGP can only be trained with unbatched gradient descent, roughly 10k observations. Does a good job for predicting the first few days of the testing set, declines to zero predictions over time. Would likely be solved by online updates of training data.\n",
    "- VariationalGP can be trained with with batched, stochastic & natural gradient descent. Only fits into GPU memory with few inducting points, because inducting points are unbatched, kind of defeating the purpose of using SGD. Does not fit & converge properly, likely due to usage of inducting points.\n",
    "- VNNGP supports batching the inducting points, essentially using the entire data as both training & inducting points. The initial computing of the k-nearest neighbor structure (when model is created, not trained) is slow, but can be made faster by installing the faiss package. The entire data can be used as inducting points, but training loss is inexplicably high (200k to 2k in 15-20 epochs), and predictions fluctate around zero seemingly randomly. Also constant warnings for negative variances are raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76fd89e6-4c21-452f-96ca-e06f9db81c34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ExactGP model class\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "    def __init__(self, X_train, y_train, likelihood):\n",
    "        super().__init__(X_train, y_train, likelihood)\n",
    "\n",
    "        # Create mean module\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        #self.mean_module = gpytorch.means.ZeroMean()\n",
    "\n",
    "        # Create covariance module\n",
    "        self.covar_module = AdditiveKernel(\n",
    "            LinearKernel(active_dims = 0),\n",
    "            #ScaleKernel(LinearKernel(active_dims = 0)),\n",
    "            ScaleKernel(PeriodicKernel(\n",
    "                active_dims = (1),\n",
    "                period_length_prior = NormalPrior(24, 1) # Hourly seasonality\n",
    "            )),\n",
    "            ScaleKernel(PeriodicKernel(\n",
    "                active_dims = (2),\n",
    "                period_length_prior = NormalPrior(7, 1) # Day of week seasonality\n",
    "            )),\n",
    "            ScaleKernel(PeriodicKernel(\n",
    "                active_dims = (3),\n",
    "                period_length_prior = NormalPrior(12, 1) # Month seasonality\n",
    "            )),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.mean_module(x)\n",
    "        covar = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74554259-6cfc-4e2f-b1ef-c62fc4c06d86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ExactGP wrapper class (unbatched gradient descent)\n",
    "class ExactGP:\n",
    "    \n",
    "    def __init__(self, model, likelihood, cuda = True):\n",
    "        self.model = model\n",
    "        self.likelihood = likelihood\n",
    "        self.cuda = cuda\n",
    "\n",
    "    # Training method\n",
    "    def train(self, X_train, y_train, max_epochs, learning_rate = 0.01, early_stop = 5, early_stop_tol = 1e-3):\n",
    "\n",
    "        # Put tensors on GPU if cuda is enabled\n",
    "        if self.cuda:\n",
    "            X_train = X_train.cuda()\n",
    "            y_train = y_train.cuda()\n",
    "            self.model = self.model.cuda()\n",
    "            self.likelihood = self.likelihood.cuda()\n",
    "\n",
    "        # Put models into training mode\n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "\n",
    "        # Create Adam optimizer with model parameters\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr = learning_rate)\n",
    "\n",
    "        # Create marginal log likelihood loss\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(max_epochs):\n",
    "\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get outputs from model\n",
    "            output = self.model(X_train)\n",
    "\n",
    "            # Calculate loss and perform backpropagation\n",
    "            loss = -mll(output, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get loss & noise values to be printed\n",
    "            loss_scalar = loss.item()\n",
    "            noise = self.model.likelihood.noise.item()\n",
    "            \n",
    "            # Initialize best loss & rounds with no improvement if first epoch\n",
    "            if epoch == 0:\n",
    "                self._best_epoch = epoch\n",
    "                self._best_loss = loss_scalar\n",
    "                self._epochs_no_improvement = 0\n",
    "                self._best_state_dict = self.model.state_dict()\n",
    "\n",
    "            # Record an epoch with no improvement\n",
    "            if self._best_loss < loss_scalar - early_stop_tol:\n",
    "                self._epochs_no_improvement += 1\n",
    "\n",
    "            # Record an improvement in the loss\n",
    "            if self._best_loss > loss_scalar + early_stop_tol:\n",
    "                self.best_epoch = epoch\n",
    "                self._best_loss = loss_scalar\n",
    "                self._epochs_no_improvement = 0\n",
    "                self._best_state_dict = self.model.state_dict()\n",
    "\n",
    "            # Print epoch summary\n",
    "            print(f\"Epoch: {epoch+1}/{max_epochs}, Loss: {loss_scalar}, Noise: {noise}, Best loss: {self._best_loss}\")\n",
    "\n",
    "            # Early stop if necessary\n",
    "            if self._epochs_no_improvement >= early_stop:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Load best checkpoint after training \n",
    "        self.model.load_state_dict(self._best_state_dict)\n",
    "            \n",
    "    # Method to update model training data (kernel hyperparameters unchanged, no additional training)\n",
    "    def update_train(self, X_update, y_update):\n",
    "        \n",
    "        # Put tensors on GPU if cuda is enabled\n",
    "        if self.cuda:\n",
    "            X_update = X_update.cuda()\n",
    "            y_update = y_update.cuda()\n",
    "\n",
    "        # Update model training data\n",
    "        self.model = self.model.get_fantasy_model(X_update, y_update)\n",
    "\n",
    "    # Predict method\n",
    "    def predict(self, X_test, cpu = True, fast_preds = False):\n",
    "\n",
    "        # Test data to GPU, if cuda enabled\n",
    "        if self.cuda:\n",
    "            X_test = X_test.cuda()\n",
    "\n",
    "        # Activate eval mode\n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "\n",
    "        # Make predictions without gradient calculation\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var(state = fast_preds):\n",
    "\n",
    "            # Returns the model posterior distribution over functions p(f*|x*, X, y)\n",
    "            # Noise is not yet added to the functions\n",
    "            f_posterior = self.model(X_test)\n",
    "\n",
    "            # Returns the predictive posterior distribution p(y*|x*, X, y)\n",
    "            # Noise is added to the functions\n",
    "            y_posterior = self.likelihood(f_posterior)\n",
    "\n",
    "            # Get posterior predictive mean & prediction intervals\n",
    "            # By default, 2 standard deviations around the mean\n",
    "            y_mean = y_posterior.mean\n",
    "            y_lower, y_upper = y_posterior.confidence_region()\n",
    "\n",
    "        # Return data to CPU if desired\n",
    "        if cpu:\n",
    "            y_mean = y_mean.cpu()\n",
    "            y_lower = y_lower.cpu()\n",
    "            y_upper = y_upper.cpu()\n",
    "\n",
    "        return y_mean, y_lower, y_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c21642-37e4-4a0f-a203-f945721ebeec",
   "metadata": {},
   "source": [
    "## Model training & testing without online updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c7f8086-da6e-46a7-9aa6-60a161aaed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create likelihood, model, wrapper\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(X_train, y_train, likelihood)\n",
    "trainer = ExactGP(model, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc1647-243c-4799-9a85-d16bf9ae9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform training\n",
    "trainer.train(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    max_epochs = 50,\n",
    "    learning_rate = 0.1,\n",
    "    early_stop = 5,\n",
    "    early_stop_tol = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4804ec-5820-4451-b081-86724e5400f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model state\n",
    "model_name = \"ExactGP1.pth\"\n",
    "torch.save(trainer.model.state_dict(), output_dir + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f86d041-c746-40ac-b735-beb033ae9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model state\n",
    "model_name = \"ExactGP1.pth\"\n",
    "state_dict = torch.load(output_dir + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a079af4-6c95-43ed-9e26-6554982a42c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update trainer with loaded model\n",
    "trainer.model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a3b36a-27f8-4139-9d8c-a4de2007a1b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument other in method wrapper_CUDA__equal)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preds_mean, preds_upper, preds_lower \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 103\u001b[0m, in \u001b[0;36mExactGP.predict\u001b[1;34m(self, X_test, cpu, fast_preds)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Make predictions without gradient calculation\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), gpytorch\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mfast_pred_var(state \u001b[38;5;241m=\u001b[39m fast_preds):\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Returns the model posterior distribution over functions p(f*|x*, X, y)\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# Noise is not yet added to the functions\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     f_posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# Returns the predictive posterior distribution p(y*|x*, X, y)\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# Noise is added to the functions\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     y_posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlikelihood(f_posterior)\n",
      "File \u001b[1;32m~\\Documents\\WorkLocal\\DataScience\\GitHub\\DeepLearningEnergyForecasting\\venv\\Lib\\site-packages\\gpytorch\\models\\exact_gp.py:283\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Posterior mode\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mon():\n\u001b[1;32m--> 283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlength_safe_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    284\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    285\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input matches the stored training data. Did you forget to call model.train()?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    286\u001b[0m                 GPInputWarning,\n\u001b[0;32m    287\u001b[0m             )\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# Get the terms that only depend on training data\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\WorkLocal\\DataScience\\GitHub\\DeepLearningEnergyForecasting\\venv\\Lib\\site-packages\\gpytorch\\models\\exact_gp.py:283\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Posterior mode\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mon():\n\u001b[1;32m--> 283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m train_input, \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m length_safe_zip(train_inputs, inputs)):\n\u001b[0;32m    284\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    285\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input matches the stored training data. Did you forget to call model.train()?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    286\u001b[0m                 GPInputWarning,\n\u001b[0;32m    287\u001b[0m             )\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# Get the terms that only depend on training data\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument other in method wrapper_CUDA__equal)"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds_mean, preds_upper, preds_lower = trainer.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129f253-74bb-4d2c-b337-8ef16ae40ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. actual, first N days of testing data\n",
    "plot_hours = 24 * 5\n",
    "plt.plot(X_test[:plot_hours, 0], y_test[:plot_hours])\n",
    "plt.plot(X_test[:plot_hours, 0], preds_mean[:plot_hours])\n",
    "plt.fill_between(X_test[:plot_hours, 0], preds_lower[:plot_hours], preds_upper[:plot_hours], alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9157ce7-a4ca-4b22-9735-a232410b3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. actual, entire test set\n",
    "plt.plot(X_test[:, 0], y_test)\n",
    "plt.plot(X_test[:, 0], preds_mean)\n",
    "plt.fill_between(X_test[:, 0], preds_lower, preds_upper, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3330554-ae25-49c2-965d-b7e9a3375d73",
   "metadata": {},
   "source": [
    "Issues to fix:\n",
    "- Loading saved model causes device mismatch between training & prediction data\n",
    "- GPU memory holdup after training\n",
    "- Predicting on entire test set likely too GPU memory intensive\n",
    "- Get rid of the wrapper and add its methods to model itself?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a84582-096d-49dc-9ae2-32165b646a80",
   "metadata": {},
   "source": [
    "## Model testing with online updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b064d59-c047-4531-9b3c-f2d2bbbc1df0",
   "metadata": {},
   "source": [
    "Use get_fantasy_model method to update trained model's training data with new input sequences. Hyperparameters are not updated, which kind of mirrors the usage of input sequnces in NN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d0c39-64ec-44f8-8c96-53f1d7ef5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation pseudocode:\n",
    "Create preds list\n",
    "Perform feature scaling\n",
    "Train until [:first_t]\n",
    "Predict on first_t + horizon\n",
    "Save preds\n",
    "For pred points in [first_t:] // stride:\n",
    "    Perform feature scaling\n",
    "    Expand training set & online train\n",
    "    Predict on first_t + eval index * stride + horizon\n",
    "    Save preds\n",
    "Concat & return preds, actual targets[first_t:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d49a9-6589-4055-86cd-0325490f5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. actual, entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d716194-ebbe-4faf-b5d1-9fafaf4e077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. actual, select sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946400b-88a9-4cb3-8397-186e8f8b6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
