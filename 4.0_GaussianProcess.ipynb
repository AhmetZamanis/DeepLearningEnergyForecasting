{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bd4214-e9ea-4058-bd70-e97ab19ac65c",
   "metadata": {},
   "source": [
    "This notebook uses the GPyTorch package to apply Gaussian Process regression to the multi-step energy consumption forecasting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08149750-e8ab-40e7-bbe8-fc184e72c1be",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a418d22-4023-4f4d-93bc-8280ed0a961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gpytorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669d2852-8794-427f-9d0a-d240d55cb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8a6d62-f05e-4689-afde-6edd36dac68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Torch settings\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fedd871b-5f69-4cab-8583-d5a58dad00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dcbe585-0804-4a60-a97e-2d3a957c0a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./OutputData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20e98cf-95b1-477f-966d-83d1d5064616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_dir + \"full_data.csv\")\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], format = \"%d:%m:%Y:%H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ac72c8-f4b5-4cce-bcc3-439640f338dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop generation columns\n",
    "gen_cols = df.columns.values[2:].tolist()\n",
    "df = df.drop(gen_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1d9ff2-4bf8-41ca-a272-a601006d0932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>consumption_MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>27412.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>26324.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>24635.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>23872.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>23194.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>35090.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>33310.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52581</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>32083.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52582</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>30469.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52583</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>30029.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52584 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  consumption_MWh\n",
       "0     2018-01-01 00:00:00         27412.81\n",
       "1     2018-01-01 01:00:00         26324.39\n",
       "2     2018-01-01 02:00:00         24635.32\n",
       "3     2018-01-01 03:00:00         23872.12\n",
       "4     2018-01-01 04:00:00         23194.89\n",
       "...                   ...              ...\n",
       "52579 2023-12-31 19:00:00         35090.93\n",
       "52580 2023-12-31 20:00:00         33310.94\n",
       "52581 2023-12-31 21:00:00         32083.96\n",
       "52582 2023-12-31 22:00:00         30469.49\n",
       "52583 2023-12-31 23:00:00         30029.91\n",
       "\n",
       "[52584 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae553b-5c8b-49c7-a486-6c5185bf111e",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a92aba0-eac9-4eb3-a5f5-2bc7ebbd3c28",
   "metadata": {},
   "source": [
    "# Using the consumption lag as a predictor would require the model to be applied autoregressively for multi-horizon forecasts.\n",
    "df[\"consumption_lag2\"] = df[\"consumption_MWh\"].shift(2)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196c616-a1ce-4339-8ab7-c83406f0dd4e",
   "metadata": {},
   "source": [
    "We do not need to cyclical encode seasonal features, as we will apply a periodic kernel to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aac49c4-dc2f-4768-8449-6b723c6127bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time columns\n",
    "\n",
    "# Trend\n",
    "df[\"trend\"] = df.index.values\n",
    "\n",
    "# Hour of day\n",
    "df[\"hour\"] = df.time.dt.hour + 1\n",
    "\n",
    "# Day of week\n",
    "df[\"dayofweek\"] = df.time.dt.dayofweek + 1\n",
    "\n",
    "# Month\n",
    "df[\"month\"] = df.time.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82996eeb-c9ae-4f26-92ca-752ed658a964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>consumption_MWh</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>27412.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>26324.39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>24635.32</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>23872.12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>23194.89</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>35090.93</td>\n",
       "      <td>52579</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>33310.94</td>\n",
       "      <td>52580</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52581</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>32083.96</td>\n",
       "      <td>52581</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52582</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>30469.49</td>\n",
       "      <td>52582</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52583</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>30029.91</td>\n",
       "      <td>52583</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52584 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  consumption_MWh  trend  hour  dayofweek  month\n",
       "0     2018-01-01 00:00:00         27412.81      0     1          1      1\n",
       "1     2018-01-01 01:00:00         26324.39      1     2          1      1\n",
       "2     2018-01-01 02:00:00         24635.32      2     3          1      1\n",
       "3     2018-01-01 03:00:00         23872.12      3     4          1      1\n",
       "4     2018-01-01 04:00:00         23194.89      4     5          1      1\n",
       "...                   ...              ...    ...   ...        ...    ...\n",
       "52579 2023-12-31 19:00:00         35090.93  52579    20          7     12\n",
       "52580 2023-12-31 20:00:00         33310.94  52580    21          7     12\n",
       "52581 2023-12-31 21:00:00         32083.96  52581    22          7     12\n",
       "52582 2023-12-31 22:00:00         30469.49  52582    23          7     12\n",
       "52583 2023-12-31 23:00:00         30029.91  52583    24          7     12\n",
       "\n",
       "[52584 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d18ff6f2-7ef9-4bde-9082-b24a1b1d2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features & target, create tensors\n",
    "X = torch.tensor(\n",
    "        df.drop([\"time\", \"consumption_MWh\"], axis = 1).values, dtype = torch.float32)\n",
    "y = torch.tensor(\n",
    "        df[\"consumption_MWh\"].values, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1cf01c5-706c-44a3-93fc-bbb5147eabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation parameters that match the sequence2sequence testing scheme\n",
    "horizon = 32 # Forecast horizon\n",
    "first_t = df[df[\"time\"] == '2022-10-18 16:00:00'].index[0] # First prediction point\n",
    "stride = 24 # Number of timesteps between each prediction point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7e420b3-8d4f-4fa9-9435-134f061ed85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial train - test split\n",
    "X_train, X_test = X[:first_t, :], X[first_t:, :]\n",
    "y_train, y_test = y[:first_t], y[first_t:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85695f2d-70d5-4c31-a16e-61dddb183f55",
   "metadata": {},
   "source": [
    "## Model & wrapper definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd89e6-4c21-452f-96ca-e06f9db81c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExactGP model class\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "\n",
    "    def __init__(self, X_train, y_train, likelihood):\n",
    "        super().__init__(X_train, y_train, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covariance_module = # Linear(trend) + Periodic(hour) + Periodic(day) + Periodic(Month)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.mean_module(x)\n",
    "        covar = self.covariance_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean, covar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74554259-6cfc-4e2f-b1ef-c62fc4c06d86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ExactGP wrapper class\n",
    "class ExactGP:\n",
    "    \n",
    "    def __init__(self, model, likelihood, cuda = True):\n",
    "        self.model = model,\n",
    "        self.likelihood = likelihood,\n",
    "        self.cuda = cuda\n",
    "\n",
    "    # Training method\n",
    "    def train(self, X_train, y_train, max_epochs, learning_rate = 1e-3, early_stop = 10, early_stop_tol = 1e-4)\n",
    "\n",
    "        # Put tensors on GPU if cuda is enabled\n",
    "        if cuda:\n",
    "            X_train = X_train.cuda()\n",
    "            y_train = y_train.cuda()\n",
    "            self.model = self.model.cuda()\n",
    "            self.likelihood = self.likelihood.cuda()\n",
    "\n",
    "        # Find optimal kernel hyperparameters\n",
    "        self.model.train()\n",
    "        self.likelihood.train()\n",
    "\n",
    "        # Create Adam optimizer with model parameters\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr = learning_rate)\n",
    "\n",
    "        # Create marginal log likelihood loss\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(self.likelihood, self.model)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(max_epochs):\n",
    "\n",
    "            # Early stop\n",
    "            if self._epochs_no_improvement >= early_stop:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get outputs from model\n",
    "            output = self.model(X_train)\n",
    "\n",
    "            # Calculate loss and perform backpropagation\n",
    "            loss = -mll(output, y_train)\n",
    "            loss.backward()\n",
    "\n",
    "            # Print epoch info & update model parameters\n",
    "            noise = self.model.likelihood.noise\n",
    "            print(f\"Epoch: {epoch+1}/{max_epochs}, Loss: {loss}, Noise: {noise}\")\n",
    "            optimizer.step()\n",
    "\n",
    "            # Initialize best loss & rounds with no improvement if first epoch\n",
    "            if epoch == 0:\n",
    "                self._best_loss = loss\n",
    "                self._epochs_no_improvement = 0\n",
    "\n",
    "            # Record an epoch with no improvement\n",
    "            if self._best_loss < loss - early_stop_tol:\n",
    "                self._epochs_no_improvement += 1\n",
    "\n",
    "            # Record an improvement in the loss\n",
    "            if self._best_loss > loss:\n",
    "                self._best_loss = loss\n",
    "                self._epochs_no_improvement = 0\n",
    "                \n",
    "    # Method to update model training data (kernel hyperparameters unchanged, no additional training)\n",
    "    def update_train(self, X_update, y_update):\n",
    "        \n",
    "        # Put tensors on GPU if cuda is enabled\n",
    "        if cuda:\n",
    "            X_update = X_update.cuda()\n",
    "            y_update = y_update.cuda()\n",
    "\n",
    "        # Update model training data\n",
    "        self.model = self.model.get_fantasy_model(X_update, y_update)\n",
    "\n",
    "    # Predict method\n",
    "    def predict(self, X_test, cpu = True, fast_preds = False)\n",
    "\n",
    "        # Test data to GPU, if cuda enabled\n",
    "        if cuda:\n",
    "            X_test = X_test.cuda()\n",
    "\n",
    "        # Activate eval mode\n",
    "        self.model.eval()\n",
    "        self.likelihood.eval()\n",
    "\n",
    "        # Make predictions without gradient calculation\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var(state = fast_preds):\n",
    "\n",
    "            # Returns the model posterior distribution over functions p(f*|x*, X, y)\n",
    "            # Noise is not yet added to the functions\n",
    "            f_posterior = self.model(X_test)\n",
    "\n",
    "            # Returns the predictive posterior distribution p(y*|x*, X, y)\n",
    "            # Noise is added to the functions\n",
    "            y_posterior = self.likelihood(f_posterior)\n",
    "\n",
    "            # Get posterior predictive mean & prediction intervals\n",
    "            # By default, 2 standard deviations around the mean\n",
    "            y_mean = y_posterior.mean()\n",
    "            y_lower, y_upper = y_posterior.confidence_region()\n",
    "\n",
    "        # Return data to CPU if desired\n",
    "        if cpu:\n",
    "            y_posterior = y_posterior.cpu()\n",
    "            y_mean = y_mean.cpu()\n",
    "            y_lower = y_lower.cpu()\n",
    "            y_upper = y_upper.cpu()\n",
    "\n",
    "        return y_posterior, y_mean, y_lower, y_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12425720-ebb0-44d7-aa74-809878345e24",
   "metadata": {},
   "source": [
    "Use get_fantasy_model method to update trained model's training data with new input sequences. Hyperparameters are not updated, which kind of mirrors the usage of input sequnces in NN models.\n",
    "\\\n",
    "Can be too slow with exact inference. In that case, look into sparse variational inference & possibly minibatch training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a84582-096d-49dc-9ae2-32165b646a80",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a3109-e1ca-4b1c-a95d-2e2e1d0f7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model & likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84594e-4b82-4aa9-8918-cec5ad560a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3d0c39-64ec-44f8-8c96-53f1d7ef5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation pseudocode:\n",
    "Create preds list\n",
    "Perform feature scaling\n",
    "Train until [:first_t]\n",
    "Predict on first_t + horizon\n",
    "Save preds\n",
    "For pred points in [first_t:] // stride:\n",
    "    Perform feature scaling\n",
    "    Expand training set & online train\n",
    "    Predict on first_t + eval index * stride + horizon\n",
    "    Save preds\n",
    "Concat & return preds, actual targets[first_t:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d49a9-6589-4055-86cd-0325490f5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. actual, entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d716194-ebbe-4faf-b5d1-9fafaf4e077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs. actual, select sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946400b-88a9-4cb3-8397-186e8f8b6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
