{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d701f02-43fd-4453-9392-efef8db0c8a9",
   "metadata": {},
   "source": [
    "This notebook applies a stateful LSTM model using PyTorch & Lightning, to get multi-step quantile energy consumption forecasts. \n",
    "\\\n",
    "It also performs the necessary data handling & preprocessing steps to get input & output sequences for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef11cc-56ac-42e0-98bc-d8e5baa08288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import lightning as L\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "#from pytorch_forecasting.metrics.quantile import QuantileLoss\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from sklearn.metrics import mean_absolute_error as mae, mean_absolute_percentage_error as mape, root_mean_squared_log_error as rmsle, mean_pinball_loss as pinball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5262f-36ee-4d06-9457-771df657d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b59f93-6e6e-4fdb-8a8b-53a7551ba5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Torch settings\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "L.seed_everything(random_seed, workers = True)\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04ab1c-13d2-43b0-9fef-de865238c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759916b7-9291-4bdd-b0f8-14eabca92e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./OutputData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595e22d-ad5e-4523-be32-1e0f06c7917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_dir + \"train_data.csv\")\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab82ca-f92d-4c00-9b57-aff3d00637fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13991eef-1a7f-4130-b82b-7ab15df29afe",
   "metadata": {},
   "source": [
    "## Data prep: Getting input & output sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a1558-0aa0-43d1-8f60-248847198b84",
   "metadata": {},
   "source": [
    "We will create a \"shifted dataset\" where each row at time T contains the following columns:\n",
    "- Target value at T (consumption lead T+1),\n",
    "- Past value at T (consumption lag T-2),\n",
    "- Time covariates at T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0e34c-d389-40ce-a095-9e155eb9f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shifted dataset, drop last row due to unknown target\n",
    "df_shifted = df.copy()\n",
    "df_shifted[\"consumption_MWh\"] = df_shifted.consumption_MWh.shift(-1)\n",
    "df_shifted = df_shifted.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd1b24-47bd-4f7f-bd98-e20dea7700d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699147e-7f37-4017-861c-6674868d35d0",
   "metadata": {},
   "source": [
    "Every input sequence will be the last 72 hours before 16:00, and every output sequence will be the next 32 hours after 16:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf65954-517b-4712-97aa-42e089573017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fixed model parameters\n",
    "n_steps = len(df_shifted) \n",
    "input_length = 72 # T-L to T hours as input\n",
    "input_dims = 10 # Consumption lag 2, trend, 6 cyclical columns + 2 Fourier pairs as features\n",
    "output_length = 32 # We are only interested in predicting T+8 to 32, but we have to predict from T+1 because we need hidden states at each time step.\n",
    "horizon_start = 0 # Output step to start loss calculation from\n",
    "quantiles = [0.025, 0.5, 0.975] # Quantiles to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da695753-60ee-4d17-8481-e27c42529c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the first 16:00 row in the data, where the index is bigger than input_length - 1. This will be the first T.\n",
    "first_t = df_shifted.loc[(df_shifted.time.dt.hour == 16) & (df_shifted.index >= input_length - 1)].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba5029-5fc0-4ab2-8f63-8c7925b9b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7dd17-e961-4cb9-8d6f-a5d25db5aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the last 16:00 row in the data, with 32 time steps after it. This will be the last T.\n",
    "last_t = df_shifted.loc[(df_shifted.time.dt.hour == 16) & (df_shifted.index + output_length - 1 <= df.index.values[-1])].index.values[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a509444b-8535-44d9-8b41-da8e04dd2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_t "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49c1ac-3f13-4df7-a39a-26b63e14dfac",
   "metadata": {},
   "source": [
    "Each input sequence will contain the following:\n",
    "- Consumption lag 2 at [T - input_length, T] (past targets),\n",
    "- Time covariates at [T - input_length + 1, T+1 ] (future known covariates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e1fee-bb5a-410f-8c90-a7cd433c8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One input sequence\n",
    "input_seq = pd.concat([\n",
    "    df_shifted.iloc[(first_t - input_length):first_t, 0], # Time\n",
    "    df_shifted.iloc[(first_t - input_length):first_t, 2], # Past target\n",
    "    df_shifted.shift(-1).iloc[(first_t - input_length):(first_t), 3:] # Future known covariates\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2532030-85c4-4e5a-86b7-1f1e95b14f2e",
   "metadata": {},
   "source": [
    "Each output sequence will contain the following:\n",
    "- Consumption at [T+1, T + output_length] (future targets),\n",
    "- Time covariates at [T+2, T + output_length + 1] (future known covariates for prediction steps after T+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddc494-b847-408a-a20f-8455c331ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One output sequence\n",
    "output_seq = pd.concat([\n",
    "    df_shifted.iloc[first_t:(first_t + output_length), 0], # Time \n",
    "    df_shifted.iloc[first_t:(first_t + output_length), 1], # Future target\n",
    "    df_shifted.shift(-1).iloc[first_t:(first_t + output_length), 3:] # Future known covariates\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8775f4-3693-4062-b8b0-c2b8932c4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq.iloc[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3e0d5-59de-467f-8562-4a13c85e0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84267ded-5c7c-4228-8b1e-4257d92be8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shifted.iloc[81:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636db66-7ab4-490c-923f-09e1e1d84190",
   "metadata": {},
   "source": [
    "In the input sequence, we pair every past target value at T with the future covariates at T+1.\n",
    "\\\n",
    "In the output sequence, we pair every future target value at T+1 with the future covariates at T+2.\n",
    "\\\n",
    "This is because the future target at T+1 and the future covariates at T+2 will be the past target & future covariates in the next prediction step. \n",
    "\\\n",
    "LSTMs and RNNs can only forecast 1 step at a time as they need hidden & cell states from the previous step. \n",
    "\\\n",
    "For validation & prediciton steps, we will replace the future targets after T+1 with predicitons from the previous step, as these will be unknown values at real prediciton time.\n",
    "\\\n",
    "During training, we still use the real target values for all prediciton steps \"in hindsight\", as training with predictions as the target may mislead the model. In a real life scenario, we'd have the \"hindsight\" values available in the historic data, just like we do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159827b9-f633-435f-88e9-4a3effda324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sequences = (last_t - first_t) // 24 + 1 # Number of 16:00 rows followed by a sufficient input / output sequence\n",
    "print(\"Number of possible sequences: \" + f\"{n_sequences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860bb74a-cf1f-405c-be9a-2d1871b8f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all sequences\n",
    "for t in range(first_t, last_t + 1, 24):\n",
    "\n",
    "    # Get input sequence\n",
    "    new_input = pd.concat([\n",
    "        df_shifted.iloc[(t - input_length):t, 0], # Time\n",
    "        df_shifted.iloc[(t - input_length):t, 2], # Past target\n",
    "        df_shifted.shift(-1).iloc[(t - input_length):t, 3:] # Future known covariates\n",
    "        ], axis = 1)\n",
    "    new_input = new_input.set_index(\"time\")\n",
    "\n",
    "    # Get output sequence\n",
    "    new_output = pd.concat([\n",
    "        df_shifted.iloc[t:(t + output_length), 0], # Time \n",
    "        df_shifted.iloc[t:(t + output_length), 1], # Future target\n",
    "        df_shifted.shift(-1).iloc[t:(t + output_length), 3:] # Future known covariates\n",
    "        ], axis = 1)\n",
    "    new_output = new_output.set_index(\"time\")\n",
    "\n",
    "    if t == first_t:\n",
    "\n",
    "        # Initialize lists of sequences\n",
    "        input_sequences = [new_input]\n",
    "        output_sequences = [new_output]\n",
    "        \n",
    "    else:\n",
    "        # Concatenate to arrays of sequences\n",
    "        input_sequences.append(new_input)\n",
    "        output_sequences.append(new_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bf525-8f95-43af-9c5c-356248ae6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ecfbe6-7de0-46bc-8435-5fc5ae5ecaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a79ac-10d9-4de2-b973-99d6d60421cc",
   "metadata": {},
   "source": [
    "## Preprocessing: Custom scaler, Torch datasets & dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016ec43-cb1b-4f43-a5e8-b1650b7eebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices for train - val - test split\n",
    "sixty_percent = int(len(input_sequences) * 0.6)\n",
    "twenty_percent = int(len(input_sequences) * 0.2)\n",
    "train_end = sixty_percent\n",
    "val_end = sixty_percent + twenty_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653354da-4abb-4dd0-b6de-b4c8b1c5e490",
   "metadata": {},
   "source": [
    "In a stateful LSTM, the last timestep's hidden & cell state for observation 1 in batch 1 will be used as the initial hidden & cell state for observation 1 in batch 2.\n",
    "\\\n",
    "Because of this, we need batches of constant size through training, val. and testing data. We'll divide the lengths of each data fold with the batch size, drop the remainder from the start of the training fold & the end of the val. & test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e763f7b-0356-4795-b1fe-63431e6bb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train - val - test split\n",
    "batch_size = 64\n",
    "\n",
    "# Training data at validation step\n",
    "tr_input, tr_output = input_sequences[0:train_end], output_sequences[0:train_end]\n",
    "remainder = len(tr_input) % batch_size\n",
    "tr_input, tr_output = tr_input[remainder:], tr_output[remainder:]\n",
    "\n",
    "# Training data at testing step\n",
    "train_input, train_output = input_sequences[0:val_end], output_sequences[0:val_end]\n",
    "remainder = len(train_input) % batch_size\n",
    "train_input, train_output = train_input[remainder:], train_output[remainder:]\n",
    "\n",
    "# Validation data\n",
    "val_input, val_output = input_sequences[train_end:val_end], output_sequences[train_end:val_end]\n",
    "remainder = len(val_input) % batch_size\n",
    "val_input, val_output = val_input[:-remainder], val_output[:-remainder]\n",
    "\n",
    "# Testing data\n",
    "test_input, test_output = input_sequences[val_end:], output_sequences[val_end:]\n",
    "remainder = len(test_input) % batch_size\n",
    "test_input, test_output = test_input[:-remainder], test_output[:-remainder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9878f96-914f-428b-b462-c040ced739f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67864f4c-7d4a-4cd2-8d81-5eaad02a786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First prediction point in testing data\n",
    "test_output[0].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbb6dc-8bb4-488f-aa19-98c76dfe73d0",
   "metadata": {},
   "source": [
    "We have to scale the past consumption & trend values in the input sequences, and the future consumption & trend values in the output sequences, because they'll be the past values as the forecast horizon expands.\n",
    "\\\n",
    "We also need the ability to backtransform the network's final predictions accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699628a-d604-4623-8446-23eafd41770c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define scaling class for sequence data\n",
    "class sequence_scaler:\n",
    "    \"\"\"\n",
    "    Takes in lists of dataframes, where each dataframe is an input or output sequence.\n",
    "\n",
    "    Returns scaled 3D numpy array of shape (observations, timesteps, features).\n",
    "    Can also backtransform scaled predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_range = (-1, 1)):\n",
    "        self.lower = feature_range[0]\n",
    "        self.upper = feature_range[1]\n",
    "\n",
    "    def fit(self, input_df, output_df):\n",
    "\n",
    "        # Get input & output sequences as 3D arrays\n",
    "        # The time index will be skipped, yielding shape (N, seq_length, seq_dims)\n",
    "        input = np.stack(input_df, axis = 0)\n",
    "        output = np.stack(output_df, axis = 0)\n",
    "\n",
    "        # Get number of dimensions\n",
    "        self.num_dimensions = input.shape[2]\n",
    "        \n",
    "        # Extract & save minimum, maximum for each dimension\n",
    "        dimensions_mini = []\n",
    "        dimensions_maxi = []\n",
    "        for dimension in range(0, self.num_dimensions):\n",
    "            min = np.min([\n",
    "                np.min(input[:, :, dimension]),\n",
    "                np.min(output[:, :, dimension])\n",
    "            ])\n",
    "            dimensions_mini.append(min)\n",
    "\n",
    "            max = np.max([\n",
    "                np.max(input[:, :, dimension]),\n",
    "                np.max(output[:, :, dimension])\n",
    "            ])\n",
    "            dimensions_maxi.append(max)\n",
    "\n",
    "        self.dimensions_mini = dimensions_mini\n",
    "        self.dimensions_maxi = dimensions_maxi\n",
    "\n",
    "    def transform(self, scale_df):\n",
    "\n",
    "        # Get sequence as 3D arrays\n",
    "        scale_array = np.stack(scale_df, axis = 0)\n",
    "\n",
    "        # Initialize list of scaled dimensions\n",
    "        scaled_dimensions = []\n",
    "\n",
    "        # Scale each dimension & append to list\n",
    "        for dimension in range(0, self.num_dimensions):\n",
    "            values = scale_array[:, :, dimension]\n",
    "            min = self.dimensions_mini[dimension]\n",
    "            max = self.dimensions_maxi[dimension]\n",
    "            std = (values - min) / (max - min)\n",
    "            scaled = std * (self.upper - self.lower) + self.lower\n",
    "            scaled_dimensions.append(scaled)\n",
    "\n",
    "        # Stack over 3rd axis & return\n",
    "        return np.stack(scaled_dimensions, axis = 2)\n",
    "\n",
    "    def backtransform_preds(self, preds_array, fitted_preds_dim = 0):\n",
    "\n",
    "        # Get n. of predicted quantiles to backtransform\n",
    "        n_quantiles = preds_array.shape[-1]\n",
    "\n",
    "        # Get the fitted mini & maxi for predictions\n",
    "        min = self.dimensions_mini[fitted_preds_dim] \n",
    "        max = self.dimensions_maxi[fitted_preds_dim]\n",
    "\n",
    "        # Initialize list of backtransformed quantiles\n",
    "        backtrafo_quantiles = []\n",
    "\n",
    "        # Backtransform each quantile & append to list\n",
    "        for quantile in range(0, n_quantiles):\n",
    "            scaled = preds_array[:, :, quantile]\n",
    "            std = (scaled - self.lower) / (self.upper - self.lower)\n",
    "            values = std * (max - min) + min\n",
    "            backtrafo_quantiles.append(values)\n",
    "            \n",
    "        # Stack over 3rd axis & return\n",
    "        return np.stack(backtrafo_quantiles, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf377421-7c99-4210-87c4-dab14581571a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Torch dataset class\n",
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Simply takes in the input & output sequences as 3D arrays and returns them as Torch tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Store preprocessed input & output sequences\n",
    "    def __init__(self, input_seq, output_seq): \n",
    "        self.input_seq = torch.tensor(input_seq, dtype = torch.float32) # Store input sequences\n",
    "        self.output_seq = torch.tensor(output_seq, dtype = torch.float32) # Store output sequences\n",
    "  \n",
    "    # Return data length  \n",
    "    def __len__(self):\n",
    "        return len(self.input_seq) \n",
    "  \n",
    "    # Return a pair of input & output sequences\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_seq[idx], self.output_seq[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf3a58-b711-4157-abf7-0f066ec713b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale validation data & create Torch datasets\n",
    "scaler_val = sequence_scaler()\n",
    "_ = scaler_val.fit(tr_input, tr_output)\n",
    "tr_data = SequenceDataset(scaler_val.transform(tr_input), scaler_val.transform(tr_output))\n",
    "val_data = SequenceDataset(scaler_val.transform(val_input), scaler_val.transform(val_output))\n",
    "\n",
    "# Scale testing data & create Torch datasets\n",
    "scaler_test = sequence_scaler()\n",
    "_ = scaler_test.fit(train_input, train_output)\n",
    "train_data = SequenceDataset(scaler_test.transform(train_input), scaler_test.transform(train_output))\n",
    "test_data = SequenceDataset(scaler_test.transform(test_input), scaler_test.transform(test_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836887aa-b98f-4441-bede-b38022c715eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Torch dataloaders\n",
    "num_workers = 0\n",
    "shuffle = False\n",
    "\n",
    "# Training data at validation step\n",
    "tr_loader = torch.utils.data.DataLoader(\n",
    "    tr_data, batch_size = batch_size, num_workers = num_workers, shuffle = shuffle)\n",
    "\n",
    "# Training data at testing step\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size = batch_size, num_workers = num_workers, shuffle = shuffle)\n",
    "\n",
    "# Validation & testing data\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data, batch_size = batch_size, num_workers = num_workers, shuffle = shuffle)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size = batch_size, num_workers = num_workers, shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c517f-376f-43e2-8839-16e9b261e80f",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd8a35-f626-4cad-8db6-4932b2e27df2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define QuantileLoss, because pytorch_forecasting installation raises issues with Python 3.12\n",
    "class QuantileLoss:\n",
    "    \"\"\"\n",
    "    Takes in targets of shape (...),\n",
    "    predictions of shape (..., n_quantiles),\n",
    "    quantiles list.\n",
    "    \n",
    "    Returns unreduced quantile loss tensor of shape (..., n_quantiles),\n",
    "    where each value is quantile loss * 2 (equal to the MAE for q = 0.5).\n",
    "    \n",
    "    Implemented from pytorch_forecasting.metrics.quantile.QuantileLoss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, quantiles):\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "    def loss(self, pred, target):\n",
    "        \n",
    "        quantile_losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            error = target - pred[..., i]\n",
    "            quantile_error = torch.max(\n",
    "                (q - 1) * error,\n",
    "                q * error\n",
    "            ).unsqueeze(-1)\n",
    "            quantile_losses.append(quantile_error)\n",
    "\n",
    "        quantile_losses = torch.cat(quantile_losses, dim = 2)\n",
    "        return quantile_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da1985-55fe-4b63-bf5a-fed283a299e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define model class\n",
    "class StatefulQuantileLSTM(L.LightningModule):\n",
    "    \"\"\"\n",
    "    Stateful LSTM forecasting model, returns quantile predictions.\n",
    "    Input & output sequences are 3D tensors of shape (batch_size, timesteps, features).\n",
    "    Hidden & cell states are retained & passed forward across training & inference batches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize model\n",
    "    def __init__(self, hyperparams_dict):\n",
    "        \n",
    "         # Delegate function to parent class\n",
    "        super().__init__() \n",
    "        \n",
    "        # Save external hyperparameters so they are available when loading saved models\n",
    "        self.save_hyperparameters(logger = False) \n",
    "\n",
    "        # Define hyperparameters\n",
    "        self.output_length = hyperparams_dict[\"output_length\"] # Length of output sequence\n",
    "        self.input_size = hyperparams_dict[\"input_size\"] # Number of features (network inputs)\n",
    "        self.horizon_start = hyperparams_dict[\"horizon_start\"] # Start of the forecast horizon relevant for loss computing\n",
    "        self.quantiles = hyperparams_dict[\"quantiles\"] # Provide as list of floats: [0.025, 0.5, 0.975]\n",
    "        self.learning_rate = hyperparams_dict[\"learning_rate\"]\n",
    "        self.lr_decay = hyperparams_dict[\"lr_decay\"]\n",
    "        self.num_layers = hyperparams_dict[\"num_layers\"] # Number of layers in the LSTM block\n",
    "        self.hidden_size = hyperparams_dict[\"hidden_size\"] # Number of units in each LSTM block = LSTM block output size\n",
    "        self.dropout_rate = hyperparams_dict[\"dropout_rate\"]\n",
    "\n",
    "        # Define architecture\n",
    "        \n",
    "        # LSTM input: input, (prev_hidden_states, prev_cell_states)\n",
    "        # Shapes: (N, input_length, input_size), ((num_layers, N, hidden_size), (num_layers, N, hidden_size))\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = self.input_size,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = True\n",
    "        )\n",
    "        # LSTM output: output, (last_hidden_states, last_cell_states)\n",
    "        # Shapes: (N, input_length, hidden_size), ((num_layers, N, hidden_size), (num_layers, N, hidden_size))\n",
    "        # \"output\" has the last layer's output / final hidden state for each timestep in the input sequence.\n",
    "        # The tuple of hidden & cell states have the last timestep's hidden & cell states for each LSTM layer.\n",
    "\n",
    "        # Output layer input: LSTM output, shape (N, 1, hidden_size)\n",
    "        # The final hidden state output for the last timestep in the input sequence.\n",
    "        self.output_layer = torch.nn.Linear(\n",
    "            in_features = self.hidden_size,\n",
    "            out_features = len(self.quantiles)\n",
    "        )\n",
    "        # Output layer output: Quantile predictions, shape (N, n_quantiles)\n",
    "\n",
    "        # Loss function: Quantile loss\n",
    "        self.loss = QuantileLoss(quantiles = self.quantiles)\n",
    "        self._median_quantile = np.median(self.quantiles)\n",
    "        self._median_quantile_idx = self.quantiles.index(self._median_quantile)\n",
    "\n",
    "        # Initialize hidden & cell state containers for statefulness\n",
    "        self._last_hiddens_train = None\n",
    "        self._last_cells_train = None\n",
    "        self._final_hiddens_train = None\n",
    "        self._final_cells_train = None\n",
    "\n",
    "    # Define forward propagation\n",
    "    # Pass prev_states as tuple (prev_hidden_states, prev_cell_states)\n",
    "    def forward(self, input_chunk, prev_states = None): \n",
    "\n",
    "        # Pass inputs through LSTMs\n",
    "        # If prev_states is not passed, they are automatically initialized as zeroes\n",
    "        if prev_states == None:\n",
    "            lstm_output, (last_hidden_states, last_cell_states) = self.lstm(input_chunk)\n",
    "        else: \n",
    "            lstm_output, (last_hidden_states, last_cell_states) = self.lstm(input_chunk, prev_states)\n",
    "\n",
    "        # Pass final LSTM output through output layer. Keep in mind this is the last layer's hidden state\n",
    "        # output for the last timestep in the input sequence.\n",
    "        preds = self.output_layer(lstm_output[:, -1, :])\n",
    "\n",
    "        return last_hidden_states, last_cell_states, preds\n",
    "\n",
    "    # Retain the computational graphs across backprop steps, so backprop across time can be performed\n",
    "    # across batches. Demands more GPU memory.\n",
    "    def backward(self, loss):\n",
    "\n",
    "        # Free the computational graph on the last step of an epoch.\n",
    "        # If this is not done, GPU memory will fill up, even after the model itself is deleted.\n",
    "        if self.trainer.is_last_batch:\n",
    "            loss.backward(retain_graph = False)\n",
    "\n",
    "        # Retain the computational graph on all steps except last in an epoch.\n",
    "        else:\n",
    "            loss.backward(retain_graph = True)\n",
    "\n",
    "    # Define training step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # Initialize variables to record horizon, hidden & cell states, predictions\n",
    "        h = 0\n",
    "        prev_hiddens = []\n",
    "        prev_cells = []\n",
    "        batch_preds = []\n",
    "\n",
    "        # Get inputs & outputs for first forecast step\n",
    "        input_sequences, output_sequences = batch\n",
    "        input_seq = input_sequences # Inputs of the forecast step 0. (N, input_length, input_size) \n",
    "        output_seq = output_sequences[:, 0, :] # Target & future covars of forecast step 0. Needed for later forecast steps. (N, input_size)\n",
    "\n",
    "        # Perform training & recording for first forecast step\n",
    "        # If a hidden & cell state is retained from the previous batch, use it. This will be the case for all batches except the first in an epoch.\n",
    "        if self._last_hiddens_train == None:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(input_seq)\n",
    "        else:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (self._last_hiddens_train, self._last_cells_train)\n",
    "            )\n",
    "\n",
    "        prev_hiddens.append(last_hidden_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        prev_cells.append(last_cell_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        batch_preds.append(preds) # 1-dimensional list. Each element has shape (N, n_quantiles)\n",
    "        h += 1\n",
    "\n",
    "        # Perform training & recording for remaining forecast steps\n",
    "        while h < self.output_length:\n",
    "\n",
    "            # Get inputs & outputs for forecast step h: \n",
    "            input_seq = torch.cat((\n",
    "                input_seq[:, 1:, :], # Inputs of the previous forecast step, with the first row dropped. (N, input_length - 1, input_size)\n",
    "                output_seq.unsqueeze(1) # Target & future covars of previous forecast step, the last row of the new input. (N, 1, input_size)\n",
    "            ), dim = 1)\n",
    "            \n",
    "            output_seq = output_sequences[:, h, :] # Target & covars. of forecast step h. Needed for later forecast steps. (N, input_size)\n",
    "\n",
    "            # Perform training & recording for forecast step h:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (prev_hiddens[h-1], prev_cells[h-1])\n",
    "            )\n",
    "            prev_hiddens.append(last_hidden_states)\n",
    "            prev_cells.append(last_cell_states)\n",
    "            batch_preds.append(preds)\n",
    "            h += 1\n",
    "\n",
    "        # Calculate quantile loss for all forecast steps starting from the horizon\n",
    "        # We're only interested in predicting from T+8 to T+32, but predictions at T+1 will depend on predictions at T,\n",
    "        # so calculating loss over all h steps is probably ideal (horizon_start = 0). The code below supports either method.\n",
    "        preds_horizon = batch_preds[self.horizon_start:] # List length (output_length - horizon_start). Each element has shape (N, n_quantiles).\n",
    "        preds_horizon = torch.stack(preds_horizon, dim = 1) # Shape (N, output_length - horizon_start, n_quantiles)\n",
    "        targets_horizon = output_sequences[:, self.horizon_start:, 0] # Target values from horizon to end of sequence. Shape(N, output_length - horizon_start)\n",
    "        loss = self.loss.loss(preds_horizon, targets_horizon) # Quantile losses for each batch & timestep. Shape (N, output_length - horizon_start, n_quantiles)\n",
    "\n",
    "        # Reduce the quantile loss\n",
    "        # A lot of room for experimentation here. Below is the typical application for RNNs. See: \n",
    "        # (https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks#overview)\n",
    "        loss_reduced = loss.mean(dim = 2) # Average over quantiles. Yields (N, output_length - horizon_start)\n",
    "        loss_reduced = loss_reduced.sum(dim = 1) # Sum over forecast steps. Yields (N)\n",
    "        loss_reduced = loss_reduced.mean() # Average over batches. Yields scalar loss for backpropagation.\n",
    "        \n",
    "        # Log the training loss\n",
    "        self.log(\"train_loss\", loss_reduced, on_step = True, on_epoch = True, prog_bar = True, logger = False)\n",
    "\n",
    "        # Update last hidden & cell states from training (for within-epoch use)\n",
    "        self._last_hiddens_train = prev_hiddens[-1]\n",
    "        self._last_cells_train = prev_cells[-1]\n",
    "\n",
    "        # Update final hidden & cell states from training (for inference)\n",
    "        self._final_hiddens_train = prev_hiddens[-1]\n",
    "        self._final_cells_train = prev_cells[-1]\n",
    "\n",
    "        return loss_reduced\n",
    "\n",
    "    # When a training epoch ends, flush the last hidden & cell states.\n",
    "    # Final hidden & cell states remain for inference.\n",
    "    def on_train_epoch_end(self):\n",
    "        self._last_hiddens_train = None\n",
    "        self._last_cells_train = None\n",
    "\n",
    "    # Method to flush the final hidden & cell states left from training, if desired\n",
    "    def reset_states(self):\n",
    "        self._final_hiddens_train = None\n",
    "        self._final_cells_train = None\n",
    "\n",
    "    # Define validation_step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        # Initialize variables to record horizon, hidden & cell states, predictions\n",
    "        h = 0\n",
    "        prev_hiddens = []\n",
    "        prev_cells = []\n",
    "        batch_preds = []\n",
    "\n",
    "        # Get inputs & outputs for first forecast step\n",
    "        input_sequences, output_sequences = batch\n",
    "        input_seq = input_sequences # Inputs of the forecast step 0. (N, input_length, input_size) \n",
    "        output_seq = output_sequences[:, 0, 1:] # Future covars of forecast step 0. Needed for later forecast steps. (N, input_size - 1)\n",
    "\n",
    "        # Perform validation & recording for first forecast step\n",
    "        # If a hidden & cell state is retained from training, use it.\n",
    "        if self._final_hiddens_train == None:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(input_seq)\n",
    "        else:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (self._final_hiddens_train, self._final_cells_train)\n",
    "            )\n",
    "\n",
    "        prev_hiddens.append(last_hidden_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        prev_cells.append(last_cell_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        batch_preds.append(preds) # 1-dimensional list. Each element has shape (N, n_quantiles)\n",
    "        h += 1\n",
    "\n",
    "        # Perform validation & recording for remaining forecast steps\n",
    "        while h < self.output_length:\n",
    "\n",
    "            # Get inputs & outputs for forecast step h:\n",
    "            output_seq = torch.cat((\n",
    "                batch_preds[h-1][:, self._median_quantile_idx].unsqueeze(1), # Point prediction of forecast step 0. (N, 1)\n",
    "                output_seq # Future covars of forecast step 0. (N, input_size - 1)\n",
    "            ), dim = 1)\n",
    "            \n",
    "            input_seq = torch.cat((\n",
    "                input_seq[:, 1:, :], # Inputs of the previous forecast step, with the first row dropped. (N, input_length - 1, input_size)\n",
    "                output_seq.unsqueeze(1) # Prediction & future covars of previous forecast step, the last row of the new input. (N, 1, input_size)\n",
    "            ), dim = 1)\n",
    "            \n",
    "            output_seq = output_sequences[:, h, 1:] # Future covars. of forecast step h. Needed for later forecast steps. (N, input_size-1)\n",
    "\n",
    "            # Perform training & recording for forecast step h:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (prev_hiddens[h-1], prev_cells[h-1])\n",
    "            )\n",
    "            prev_hiddens.append(last_hidden_states)\n",
    "            prev_cells.append(last_cell_states)\n",
    "            batch_preds.append(preds)\n",
    "            h += 1\n",
    "\n",
    "        # Calculate loss for forecast steps starting from horizon\n",
    "        preds_horizon = batch_preds[self.horizon_start:] # List length (output_length - horizon_start). Each element has shape (N, n_quantiles).\n",
    "        preds_horizon = torch.stack(preds_horizon, dim = 1) # Shape (N, output_length - horizon_start, n_quantiles)\n",
    "        targets_horizon = output_sequences[:, self.horizon_start:, 0] # Target values from horizon to end of sequence. Shape(N, output_length - horizon_start)\n",
    "        loss = self.loss.loss(preds_horizon, targets_horizon) # Quantile losses for each batch & timestep. Shape (N, output_length - horizon_start, n_quantiles)\n",
    "\n",
    "        # Reduce the quantile loss\n",
    "        loss_reduced = loss.mean(dim = 2) # Average over quantiles. Yields (N, output_length - horizon_start)\n",
    "        loss_reduced = loss_reduced.sum(dim = 1) # Sum over forecast steps. Yields (N)\n",
    "        loss_reduced = loss_reduced.mean() # Average over batches. Yields scalar loss for backpropagation.\n",
    "\n",
    "        # Log the val. loss\n",
    "        self.log(\"val_loss\", loss_reduced, on_step = True, on_epoch = True, prog_bar = True, logger = False)\n",
    "\n",
    "        return loss_reduced\n",
    "\n",
    "    # Define prediction_step\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "\n",
    "        # Initialize variables to record horizon, hidden & cell states, predictions\n",
    "        h = 0\n",
    "        prev_hiddens = []\n",
    "        prev_cells = []\n",
    "        batch_preds = []\n",
    "\n",
    "        # Get inputs & outputs for first forecast step\n",
    "        input_sequences, output_sequences = batch\n",
    "        input_seq = input_sequences # Inputs of the forecast step 0. (N, input_length, input_size) \n",
    "        output_seq = output_sequences[:, 0, 1:] # Future covars of forecast step 0. Needed for later forecast steps. (N, input_size - 1)\n",
    "\n",
    "        # Perform prediction & recording for first forecast step\n",
    "        # If a hidden & cell state is retained from training, use it.\n",
    "        if self._final_hiddens_train == None:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(input_seq)\n",
    "        else:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (self._final_hiddens_train, self._final_cells_train)\n",
    "            )\n",
    "\n",
    "        prev_hiddens.append(last_hidden_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        prev_cells.append(last_cell_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        batch_preds.append(preds) # 1-dimensional list. Each element has shape (N, n_quantiles)\n",
    "        h += 1\n",
    "\n",
    "        # Perform prediction & recording for remaining forecast steps\n",
    "        while h < self.output_length:\n",
    "\n",
    "            # Get inputs & outputs for forecast step h:\n",
    "            output_seq = torch.cat((\n",
    "                batch_preds[h-1][:, self._median_quantile_idx].unsqueeze(1), # Point prediction of forecast step 0. (N, 1)\n",
    "                output_seq # Future covars of forecast step 0. (N, input_size - 1)\n",
    "            ), dim = 1)\n",
    "            \n",
    "            input_seq = torch.cat((\n",
    "                input_seq[:, 1:, :], # Inputs of the previous forecast step, with the first row dropped. (N, input_length - 1, input_size)\n",
    "                output_seq.unsqueeze(1) # Prediction & future covars of previous forecast step, the last row of the new input. (N, 1, input_size)\n",
    "            ), dim = 1)\n",
    "            \n",
    "            output_seq = output_sequences[:, h, 1:] # Future covars. of forecast step h. Needed for later forecast steps. (N, input_size-1)\n",
    "\n",
    "            # Perform training & recording for forecast step h:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (prev_hiddens[h-1], prev_cells[h-1])\n",
    "            )\n",
    "            prev_hiddens.append(last_hidden_states)\n",
    "            prev_cells.append(last_cell_states)\n",
    "            batch_preds.append(preds)\n",
    "            h += 1\n",
    "\n",
    "        # Reshape predictions\n",
    "        preds = torch.stack(batch_preds, dim = 0) # Yields shape (output_length, N, n_quantiles)\n",
    "        preds = torch.movedim(preds, 1, 0) # Yields shape (N, output_length, n_quantiles)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    # Define optimizer & learning rate scheduler\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # Adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "        \n",
    "        # Exponential LR scheduler\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "          optimizer, gamma = self.lr_decay) \n",
    "        \n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "          \"scheduler\": lr_scheduler\n",
    "          }\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efdf47-113d-49dd-8214-3cb2a4ff9c43",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42fa951-e14b-49c6-8c20-98685c0adeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tuning parameters\n",
    "tol = 0.002 # Change in MAE to avoid early stopping\n",
    "patience = 5 # N. of rounds with no improvement before early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfd441-0457-45fe-9e5f-a8f2942c6056",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define Optuna objective\n",
    "def objective_lstm(trial):\n",
    "\n",
    "    # Define search space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-4, 5e-2) # 0.0005 to 0.05\n",
    "    lr_decay = trial.suggest_float(\"lr_decay\", 0.9, 1)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
    "    hidden_size = 2 ** trial.suggest_int(\"hidden_size_pw\", 2, 8) # 4 to 128, powers of 2\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.1)\n",
    "\n",
    "    # Create hyperparameters dict\n",
    "    hyperparameters_dict = {\n",
    "        \"output_length\": output_length,\n",
    "        \"input_size\": input_dims,\n",
    "        \"horizon_start\": horizon_start,\n",
    "        \"quantiles\": quantiles,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"lr_decay\": lr_decay,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"dropout_rate\": dropout_rate\n",
    "    }\n",
    "\n",
    "    # Create early stop callback\n",
    "    callback_earlystop = L.pytorch.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\", \n",
    "        mode = \"min\", \n",
    "        min_delta = tol, \n",
    "        patience = patience\n",
    "    )\n",
    "\n",
    "    # Create pruning callback\n",
    "    callback_pruner = PyTorchLightningPruningCallback(trial, monitor = \"val_loss\")\n",
    "\n",
    "    # Create trainer\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs = 50,\n",
    "        accelerator = \"gpu\",\n",
    "        devices = \"auto\",\n",
    "        precision = \"16-mixed\",\n",
    "        callbacks = [callback_earlystop, callback_pruner],\n",
    "        enable_model_summary = False,\n",
    "        logger = False,\n",
    "        enable_progress_bar = False,\n",
    "        enable_checkpointing = False\n",
    "    )\n",
    "\n",
    "    # Create & train model\n",
    "    model = StatefulQuantileLSTM(hyperparameters_dict)\n",
    "    trainer.fit(model, tr_loader, val_loader)\n",
    "\n",
    "    # Retrieve best val score and n. of epochs\n",
    "    score = callback_earlystop.best_score.cpu().numpy()\n",
    "    epoch = trainer.current_epoch - callback_earlystop.wait_count # Starts from 1\n",
    "\n",
    "    # Report best n. of epochs to study\n",
    "    trial.set_user_attr(\"n_epochs\", epoch)\n",
    "  \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574517f-1bfc-41f3-b7a1-e2a44d751696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create study\n",
    "study_lstm = optuna.create_study(\n",
    "  sampler = optuna.samplers.TPESampler(seed = random_seed),\n",
    "  pruner = optuna.pruners.HyperbandPruner(),\n",
    "  study_name = \"tune_lstm\",\n",
    "  direction = \"minimize\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099ce40-0f12-4ef5-8702-2eb6509bacea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize study\n",
    "study_lstm.optimize(objective_lstm, n_trials = 500, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bae9ca-011f-4653-816f-976f0393b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and export trials\n",
    "export_trial_no = \"4\"\n",
    "trials_lstm = study_lstm.trials_dataframe().sort_values(\"value\", ascending = True)\n",
    "trials_lstm.to_csv(f\"./OutputData/trials_lstm{export_trial_no}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425b0d3-852e-4f68-9c2f-eba6f18d3043",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e30c250-b6c3-4770-9956-38d58f666135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import best trial\n",
    "import_trial_no = \"4\"\n",
    "best_trial_lstm= pd.read_csv(f\"./OutputData/trials_lstm{import_trial_no}.csv\").iloc[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faea85-1885-4e39-858c-7b98e529c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49e3d8-26e5-44b1-af10-848cfb0bd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameters dict\n",
    "hyperparameters_dict = {\n",
    "    \"output_length\": output_length,\n",
    "    \"input_size\": input_dims,\n",
    "    \"horizon_start\": horizon_start,\n",
    "    \"quantiles\": quantiles,\n",
    "    \"learning_rate\": best_trial_lstm[\"params_learning_rate\"],\n",
    "    \"lr_decay\": best_trial_lstm[\"params_lr_decay\"],\n",
    "    \"num_layers\": best_trial_lstm[\"params_num_layers\"],\n",
    "    \"hidden_size\": int(2 ** best_trial_lstm[\"params_hidden_size_pw\"]),\n",
    "    \"dropout_rate\": best_trial_lstm[\"params_dropout_rate\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517c633-90b1-49f0-8ae1-1e3b4ab87314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs = int(best_trial_lstm[\"user_attrs_n_epochs\"]),\n",
    "    accelerator = \"gpu\",\n",
    "    devices = \"auto\",\n",
    "    precision = \"16-mixed\",\n",
    "    enable_model_summary = True,\n",
    "    logger = False,\n",
    "    enable_progress_bar = True,\n",
    "    enable_checkpointing = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa853b4b-e694-4c14-a14a-84eaf6bae6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & train model\n",
    "model = StatefulQuantileLSTM(hyperparameters_dict)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66ee1e-d4cc-47d6-8298-656e219725c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data & backtransform scaled values\n",
    "preds_raw = trainer.predict(model, test_loader)\n",
    "preds_raw = torch.cat(preds_raw, dim = 0).cpu().numpy().astype(np.float32)\n",
    "preds = scaler_test.backtransform_preds(preds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20117b-eced-4518-9eb7-c198e3208ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine back prediction sequences with times\n",
    "test_dates = np.stack([sequence.index for sequence in test_output], axis = 0)\n",
    "df_preds = pd.DataFrame({\n",
    "    \"time\": np.ravel(test_dates),\n",
    "    \"pred_low\": np.ravel(preds[:, :, 0]),\n",
    "    \"pred_point\": np.ravel(preds[:, :, 1]),\n",
    "    \"pred_high\": np.ravel(preds[:, :, 2])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e257d78-6ee2-4987-9884-3d66ce4fd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82f259-e2e6-43ca-891c-1372339ed4c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Combine back testing output sequences with input sequences & times\n",
    "\n",
    "# Create dataframe from all input sequences\n",
    "test_output_stacked = np.stack(test_output, axis = 0)\n",
    "df_test_output = pd.DataFrame({\n",
    "    \"time\": np.ravel(test_dates),\n",
    "    \"consumption_MWh\": np.ravel(test_output_stacked[:, :, 0])\n",
    "})\n",
    "df_test_output[\"time\"] = pd.to_datetime(df_test_output[\"time\"])\n",
    "\n",
    "# Create dataframe from all input sequences\n",
    "test_input_dates = np.stack([sequence.index for sequence in test_input], axis = 0)\n",
    "test_input_stacked = np.stack(test_input, axis = 0)\n",
    "df_test_input = pd.DataFrame({\n",
    "    \"time\": np.ravel(test_input_dates),\n",
    "    \"consumption_MWh\" : np.ravel(test_input_stacked[:, :, 0])\n",
    "})\n",
    "df_test_input[\"time\"] = pd.to_datetime(df_test_input[\"time\"])\n",
    "\n",
    "# Concatenate & sort by time\n",
    "df_test = pd.concat([df_test_output, df_test_input])\n",
    "df_test = df_test.sort_values(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b9fd9-f804-47d9-876b-3d0fc3959d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2fa23-50d0-4933-8301-86047279f13c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Predicted vs. actual plot, hourly, entire test period\n",
    "_ = sns.lineplot(\n",
    "    data = df_test,\n",
    "    x = \"time\",\n",
    "    y = \"consumption_MWh\",\n",
    "    label = \"Actual values\"\n",
    ")\n",
    "\n",
    "_ = sns.lineplot(\n",
    "    data = df_preds,\n",
    "    x = \"time\",\n",
    "    y = \"pred_point\",\n",
    "    label = \"Predictions, 95% quantile interval\"\n",
    ")\n",
    "\n",
    "_ = plt.fill_between(\n",
    "    x = df_preds.time,\n",
    "    y1 = df_preds.pred_low,\n",
    "    y2 = df_preds.pred_high,\n",
    "    label = \"95% prediction interval\",\n",
    "    color = \"orange\",\n",
    "    alpha = 0.4\n",
    ")\n",
    "_ = plt.title(\"Model: Stateful LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de114a52-3a39-46a2-9902-d31b1f522c0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_sequence_preds(preds, input_sequences, output_sequences, sequence_index = 0, model = \"Stateful LSTM\"):\n",
    "\n",
    "    # Get n. of sequences\n",
    "    n_sequences = len(output_sequences)\n",
    "    \n",
    "    # Get predictions for selected sequence\n",
    "    preds_low = preds[sequence_index, :, 0]\n",
    "    preds_point = preds[sequence_index, :, 1]\n",
    "    preds_high = preds[sequence_index, :, 2]\n",
    "\n",
    "    # Get & combine actual outputs, inputs, dates\n",
    "    date_output = output_sequences[sequence_index].index.to_series()\n",
    "    output = output_sequences[sequence_index].consumption_MWh.values\n",
    "    \n",
    "    date_input = input_sequences[sequence_index].index.to_series()\n",
    "    input = input_sequences[sequence_index].consumption_lag2.values\n",
    "\n",
    "    date = pd.concat([date_input, date_output], axis = 0)\n",
    "    actual = np.concatenate([input, output], axis = 0)\n",
    "\n",
    "    # Plot\n",
    "    _ = sns.lineplot(\n",
    "        x = date,\n",
    "        y = actual,\n",
    "        label = \"Actual values\"\n",
    "    )\n",
    "\n",
    "    _ = sns.lineplot(\n",
    "        x = date_output,\n",
    "        y = preds_point,\n",
    "        label = \"Predictions\"\n",
    "    )\n",
    "    \n",
    "    _ = plt.fill_between(\n",
    "        x = date_output,\n",
    "        y1 = preds_low,\n",
    "        y2 = preds_high,\n",
    "        color = \"orange\",\n",
    "        alpha = 0.4\n",
    "    )\n",
    "\n",
    "    _ = plt.title(f\"Model: {model},\\n Sequence index: {sequence_index} of {n_sequences - 1}\")\n",
    "    _ = plt.xlabel(\"time\")\n",
    "    _ = plt.ylabel(\"consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc5993-8e19-48f9-b1d6-db9f1c66b28a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Predicted vs. actual plots, zoomed in\n",
    "indices = [i for i in range(0, len(test_output), len(test_output) // 4)]\n",
    "indices.append(len(test_output) - 1)\n",
    "for idx in indices:\n",
    "    plt.figure()\n",
    "    plot_sequence_preds(preds, test_input, test_output, sequence_index = idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7b372-0c26-41f5-a27b-b080727bc869",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate performance metrics: MAE, RMSLE, MAPE, pinball\n",
    "rounding = 4\n",
    "pd.DataFrame([\n",
    "    mape(df_test_output.consumption_MWh, df_preds.pred_point) * 100,\n",
    "    rmsle(df_test_output.consumption_MWh, df_preds.pred_point),\n",
    "    mae(df_test_output.consumption_MWh, df_preds.pred_point),\n",
    "    pinball(df_test_output.consumption_MWh, df_preds.pred_point, alpha = quantiles[0]),\n",
    "    pinball(df_test_output.consumption_MWh, df_preds.pred_point, alpha = quantiles[1]),\n",
    "    pinball(df_test_output.consumption_MWh, df_preds.pred_point, alpha = quantiles[-1])\n",
    "], columns = [\"Model: Stateful quantile LSTM\"],\n",
    "index = [ \n",
    "    \"MAPE, point\", \n",
    "    \"RMSLE, point\",\n",
    "    \"MAE, point\",\n",
    "    f\"Pinball loss, q: {quantiles[0] * 100}%\",\n",
    "    f\"Pinball loss, q: {quantiles[1] * 100}%\",\n",
    "    f\"Pinball loss, q: {quantiles[-1] * 100}%\"\n",
    "]).round(rounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d58f5e-0e4e-4ead-bc40-23152ccf4885",
   "metadata": {},
   "source": [
    "Keep in mind that for the median quantile, pinball loss equals MAE / 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
