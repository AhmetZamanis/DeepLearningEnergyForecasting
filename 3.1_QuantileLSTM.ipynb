{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ef11cc-56ac-42e0-98bc-d8e5baa08288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Documents\\WorkLocal\\DataScience\\GitHub\\DeepLearningEnergyForecasting\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning as L\n",
    "import optuna\n",
    "\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss\n",
    "from optuna.integration.pytorch_lightning import PyTorchLightningPruningCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759916b7-9291-4bdd-b0f8-14eabca92e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./OutputData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3595e22d-ad5e-4523-be32-1e0f06c7917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_dir + \"train_data.csv\")\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ab82ca-f92d-4c00-9b57-aff3d00637fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>consumption_MWh</th>\n",
       "      <th>consumption_lag2</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>24635.32</td>\n",
       "      <td>27412.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>23872.12</td>\n",
       "      <td>26324.39</td>\n",
       "      <td>3</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>23194.89</td>\n",
       "      <td>24635.32</td>\n",
       "      <td>4</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 05:00:00</td>\n",
       "      <td>23071.96</td>\n",
       "      <td>23872.12</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>23267.90</td>\n",
       "      <td>23194.89</td>\n",
       "      <td>6</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52577</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>35090.93</td>\n",
       "      <td>34549.42</td>\n",
       "      <td>52579</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52578</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>33310.94</td>\n",
       "      <td>36193.59</td>\n",
       "      <td>52580</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>32083.96</td>\n",
       "      <td>35090.93</td>\n",
       "      <td>52581</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>30469.49</td>\n",
       "      <td>33310.94</td>\n",
       "      <td>52582</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52581</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>30029.91</td>\n",
       "      <td>32083.96</td>\n",
       "      <td>52583</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52582 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time  consumption_MWh  consumption_lag2  trend  \\\n",
       "0     2018-01-01 02:00:00         24635.32          27412.81      2   \n",
       "1     2018-01-01 03:00:00         23872.12          26324.39      3   \n",
       "2     2018-01-01 04:00:00         23194.89          24635.32      4   \n",
       "3     2018-01-01 05:00:00         23071.96          23872.12      5   \n",
       "4     2018-01-01 06:00:00         23267.90          23194.89      6   \n",
       "...                   ...              ...               ...    ...   \n",
       "52577 2023-12-31 19:00:00         35090.93          34549.42  52579   \n",
       "52578 2023-12-31 20:00:00         33310.94          36193.59  52580   \n",
       "52579 2023-12-31 21:00:00         32083.96          35090.93  52581   \n",
       "52580 2023-12-31 22:00:00         30469.49          33310.94  52582   \n",
       "52581 2023-12-31 23:00:00         30029.91          32083.96  52583   \n",
       "\n",
       "           hour_sin      hour_cos       day_sin  day_cos     month_sin  \\\n",
       "0      7.071068e-01  7.071068e-01  7.818315e-01  0.62349  5.000000e-01   \n",
       "1      8.660254e-01  5.000000e-01  7.818315e-01  0.62349  5.000000e-01   \n",
       "2      9.659258e-01  2.588190e-01  7.818315e-01  0.62349  5.000000e-01   \n",
       "3      1.000000e+00  6.123234e-17  7.818315e-01  0.62349  5.000000e-01   \n",
       "4      9.659258e-01 -2.588190e-01  7.818315e-01  0.62349  5.000000e-01   \n",
       "...             ...           ...           ...      ...           ...   \n",
       "52577 -8.660254e-01  5.000000e-01 -2.449294e-16  1.00000 -2.449294e-16   \n",
       "52578 -7.071068e-01  7.071068e-01 -2.449294e-16  1.00000 -2.449294e-16   \n",
       "52579 -5.000000e-01  8.660254e-01 -2.449294e-16  1.00000 -2.449294e-16   \n",
       "52580 -2.588190e-01  9.659258e-01 -2.449294e-16  1.00000 -2.449294e-16   \n",
       "52581 -2.449294e-16  1.000000e+00 -2.449294e-16  1.00000 -2.449294e-16   \n",
       "\n",
       "       month_cos  \n",
       "0       0.866025  \n",
       "1       0.866025  \n",
       "2       0.866025  \n",
       "3       0.866025  \n",
       "4       0.866025  \n",
       "...          ...  \n",
       "52577   1.000000  \n",
       "52578   1.000000  \n",
       "52579   1.000000  \n",
       "52580   1.000000  \n",
       "52581   1.000000  \n",
       "\n",
       "[52582 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13991eef-1a7f-4130-b82b-7ab15df29afe",
   "metadata": {},
   "source": [
    "## Data prep: Getting input & output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce0c2bb-c679-47c0-9121-541b7fec3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_target = df.consumption_lag2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ab9e5e-5059-444f-a6c4-06f482a564a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_covars = df.drop([\"time\", \"consumption_MWh\", \"consumption_lag2\"], axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c79992d-2169-4954-ad9b-8dc8fe45078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_covars = df.drop([\"time\", \"consumption_MWh\", \"consumption_lag2\"], axis = 1).shift(-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd091fe-bef0-4150-9092-cf406a0ec9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_target = df.consumption_MWh.shift(-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88add024-91bf-4f64-b570-a35a33894211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27412.81, 26324.39, 24635.32, ..., 35090.93, 33310.94, 32083.96])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the consumption_lag2 value at T\n",
    "past_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4587b436-bce0-439e-8233-9c4afbf0400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23872.12, 23194.89, 23071.96, ..., 30469.49, 30029.91,      nan])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is consumption_MWh at T+1, the target value at T\n",
    "future_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0792cda8-94e7-4efb-8dbd-d76ae3d7cd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00000000e+00,  7.07106781e-01,  7.07106781e-01, ...,\n",
       "         6.23489802e-01,  5.00000000e-01,  8.66025404e-01],\n",
       "       [ 3.00000000e+00,  8.66025404e-01,  5.00000000e-01, ...,\n",
       "         6.23489802e-01,  5.00000000e-01,  8.66025404e-01],\n",
       "       [ 4.00000000e+00,  9.65925826e-01,  2.58819045e-01, ...,\n",
       "         6.23489802e-01,  5.00000000e-01,  8.66025404e-01],\n",
       "       ...,\n",
       "       [ 5.25810000e+04, -5.00000000e-01,  8.66025404e-01, ...,\n",
       "         1.00000000e+00, -2.44929360e-16,  1.00000000e+00],\n",
       "       [ 5.25820000e+04, -2.58819045e-01,  9.65925826e-01, ...,\n",
       "         1.00000000e+00, -2.44929360e-16,  1.00000000e+00],\n",
       "       [ 5.25830000e+04, -2.44929360e-16,  1.00000000e+00, ...,\n",
       "         1.00000000e+00, -2.44929360e-16,  1.00000000e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the trend & seasonality features at T (historic future covariates)\n",
    "historic_covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5380f3b7-be0d-4a4d-963f-a6575d37226d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.00000000e+00,  8.66025404e-01,  5.00000000e-01, ...,\n",
       "         6.23489802e-01,  5.00000000e-01,  8.66025404e-01],\n",
       "       [ 4.00000000e+00,  9.65925826e-01,  2.58819045e-01, ...,\n",
       "         6.23489802e-01,  5.00000000e-01,  8.66025404e-01],\n",
       "       [ 5.00000000e+00,  1.00000000e+00,  6.12323400e-17, ...,\n",
       "         6.23489802e-01,  5.00000000e-01,  8.66025404e-01],\n",
       "       ...,\n",
       "       [ 5.25820000e+04, -2.58819045e-01,  9.65925826e-01, ...,\n",
       "         1.00000000e+00, -2.44929360e-16,  1.00000000e+00],\n",
       "       [ 5.25830000e+04, -2.44929360e-16,  1.00000000e+00, ...,\n",
       "         1.00000000e+00, -2.44929360e-16,  1.00000000e+00],\n",
       "       [            nan,             nan,             nan, ...,\n",
       "                    nan,             nan,             nan]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the trend & seasonality features at T+1 (future covariates)\n",
    "future_covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e9036ff-ff66-49a1-aaa9-4909e029e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of last rows due to unknown future target\n",
    "past_target = past_target[:-1]\n",
    "future_target = future_target[:-1]\n",
    "historic_covars = historic_covars[:-1, :]\n",
    "future_covars = future_covars[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43454623-2e48-4579-b496-d80914647bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past target shape: (52581,)\n",
      "Historic future covariates shape: (52581, 7)\n",
      "Future target shape: (52581,)\n",
      "Future covariates shape: (52581, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(\"Past target shape: \" f\"{past_target.shape}\")\n",
    "print(\"Historic future covariates shape: \" f\"{historic_covars.shape}\")\n",
    "print(\"Future target shape: \" f\"{future_target.shape}\")\n",
    "print(\"Future covariates shape: \" f\"{future_covars.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f45dd097-1e03-4871-a912-2f3048b200b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shifted datasets\n",
    "df_past = pd.DataFrame(\n",
    "    np.concatenate((past_target.reshape(-1, 1), historic_covars), axis = 1),\n",
    "    columns = df.columns.values[2:]\n",
    ")\n",
    "df_future = pd.DataFrame(\n",
    "    np.concatenate((future_target.reshape(-1, 1), future_covars), axis = 1),\n",
    "    columns = df.columns.values[2:]\n",
    ").rename({\"consumption_lag2\": \"consumption_MWh\"}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4c11eac-1984-4a17-994b-dd960db93563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumption_lag2</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27412.81</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26324.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24635.32</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23872.12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23194.89</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52576</th>\n",
       "      <td>32670.06</td>\n",
       "      <td>52578.0</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52577</th>\n",
       "      <td>34549.42</td>\n",
       "      <td>52579.0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52578</th>\n",
       "      <td>36193.59</td>\n",
       "      <td>52580.0</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>35090.93</td>\n",
       "      <td>52581.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>33310.94</td>\n",
       "      <td>52582.0</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52581 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       consumption_lag2    trend  hour_sin      hour_cos       day_sin  \\\n",
       "0              27412.81      2.0  0.707107  7.071068e-01  7.818315e-01   \n",
       "1              26324.39      3.0  0.866025  5.000000e-01  7.818315e-01   \n",
       "2              24635.32      4.0  0.965926  2.588190e-01  7.818315e-01   \n",
       "3              23872.12      5.0  1.000000  6.123234e-17  7.818315e-01   \n",
       "4              23194.89      6.0  0.965926 -2.588190e-01  7.818315e-01   \n",
       "...                 ...      ...       ...           ...           ...   \n",
       "52576          32670.06  52578.0 -0.965926  2.588190e-01 -2.449294e-16   \n",
       "52577          34549.42  52579.0 -0.866025  5.000000e-01 -2.449294e-16   \n",
       "52578          36193.59  52580.0 -0.707107  7.071068e-01 -2.449294e-16   \n",
       "52579          35090.93  52581.0 -0.500000  8.660254e-01 -2.449294e-16   \n",
       "52580          33310.94  52582.0 -0.258819  9.659258e-01 -2.449294e-16   \n",
       "\n",
       "       day_cos     month_sin  month_cos  \n",
       "0      0.62349  5.000000e-01   0.866025  \n",
       "1      0.62349  5.000000e-01   0.866025  \n",
       "2      0.62349  5.000000e-01   0.866025  \n",
       "3      0.62349  5.000000e-01   0.866025  \n",
       "4      0.62349  5.000000e-01   0.866025  \n",
       "...        ...           ...        ...  \n",
       "52576  1.00000 -2.449294e-16   1.000000  \n",
       "52577  1.00000 -2.449294e-16   1.000000  \n",
       "52578  1.00000 -2.449294e-16   1.000000  \n",
       "52579  1.00000 -2.449294e-16   1.000000  \n",
       "52580  1.00000 -2.449294e-16   1.000000  \n",
       "\n",
       "[52581 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "190ff97f-d079-4989-bb6d-bdc979fc5da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumption_MWh</th>\n",
       "      <th>trend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23872.12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23194.89</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23071.96</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23267.90</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23875.44</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>7.818315e-01</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52576</th>\n",
       "      <td>35090.93</td>\n",
       "      <td>52579.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52577</th>\n",
       "      <td>33310.94</td>\n",
       "      <td>52580.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52578</th>\n",
       "      <td>32083.96</td>\n",
       "      <td>52581.0</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>30469.49</td>\n",
       "      <td>52582.0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>30029.91</td>\n",
       "      <td>52583.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52581 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       consumption_MWh    trend      hour_sin      hour_cos       day_sin  \\\n",
       "0             23872.12      3.0  8.660254e-01  5.000000e-01  7.818315e-01   \n",
       "1             23194.89      4.0  9.659258e-01  2.588190e-01  7.818315e-01   \n",
       "2             23071.96      5.0  1.000000e+00  6.123234e-17  7.818315e-01   \n",
       "3             23267.90      6.0  9.659258e-01 -2.588190e-01  7.818315e-01   \n",
       "4             23875.44      7.0  8.660254e-01 -5.000000e-01  7.818315e-01   \n",
       "...                ...      ...           ...           ...           ...   \n",
       "52576         35090.93  52579.0 -8.660254e-01  5.000000e-01 -2.449294e-16   \n",
       "52577         33310.94  52580.0 -7.071068e-01  7.071068e-01 -2.449294e-16   \n",
       "52578         32083.96  52581.0 -5.000000e-01  8.660254e-01 -2.449294e-16   \n",
       "52579         30469.49  52582.0 -2.588190e-01  9.659258e-01 -2.449294e-16   \n",
       "52580         30029.91  52583.0 -2.449294e-16  1.000000e+00 -2.449294e-16   \n",
       "\n",
       "       day_cos     month_sin  month_cos  \n",
       "0      0.62349  5.000000e-01   0.866025  \n",
       "1      0.62349  5.000000e-01   0.866025  \n",
       "2      0.62349  5.000000e-01   0.866025  \n",
       "3      0.62349  5.000000e-01   0.866025  \n",
       "4      0.62349  5.000000e-01   0.866025  \n",
       "...        ...           ...        ...  \n",
       "52576  1.00000 -2.449294e-16   1.000000  \n",
       "52577  1.00000 -2.449294e-16   1.000000  \n",
       "52578  1.00000 -2.449294e-16   1.000000  \n",
       "52579  1.00000 -2.449294e-16   1.000000  \n",
       "52580  1.00000 -2.449294e-16   1.000000  \n",
       "\n",
       "[52581 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cf65954-517b-4712-97aa-42e089573017",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = len(df_future)\n",
    "input_length = 72 # T-N to T hours as input\n",
    "input_dims = 8 # Consumption lag 2, trend, 6 cyclical columns\n",
    "output_length = 32 # We are only interested in T+8 to 32, but we have to predict from T+1 because we need hidden states at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da695753-60ee-4d17-8481-e27c42529c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the first 16:00 row in the data, where the index is bigger than input_length - 1. This will be the first T.\n",
    "first_t = df.loc[(df.time.dt.hour == 16) & (df.index >= input_length - 1)].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efba5029-5fc0-4ab2-8f63-8c7925b9b97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ae7dd17-e961-4cb9-8d6f-a5d25db5aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the last 16:00 row in the data, with 32 time steps after it. This will be the last T.\n",
    "last_t = df.loc[(df.time.dt.hour == 16) & (df.index + output_length - 1 <= df.index.values[-1])].index.values[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a509444b-8535-44d9-8b41-da8e04dd2040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52526"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "355e1fee-bb5a-410f-8c90-a7cd433c8209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One input sequence: past target [T - input_length, T] & future covariates [T - input_length - 1, T+1]\n",
    "input_seq = np.concatenate((\n",
    "        df_past.iloc[(first_t - input_length):first_t, 0].values.reshape(-1, 1), # Past target\n",
    "        df_future.iloc[(first_t - input_length):first_t, 1:].values # Future covariates\n",
    "    ), axis = 1)\n",
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cddc494-b847-408a-a20f-8455c331ebc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One output sequence: future target [T + 1, T + output_length] & future covariates [T+2, T + output_length + 1].\n",
    "output_seq = df_future.iloc[first_t:(first_t + output_length), :].values # Target & future covariates for following steps\n",
    "output_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8636db66-7ab4-490c-923f-09e1e1d84190",
   "metadata": {},
   "source": [
    "We pair every target value at T+1 with the future covariates of the target value at T+2.\n",
    "\\\n",
    "This is because the target at T+1 and the future covariates at T+2 will be past target & future covariates in the next step. LSTMs and RNNs can only forecast 1 step at a time by their nature. \n",
    "\\\n",
    "For validation & prediciton steps, we will replace the future targets after T+1 with predicitons from the previous step, as these will be unknown values at real prediciton time.\n",
    "\\\n",
    "During training, we still use the real target values for all prediciton steps \"in hindsight\", as training with predictions as the target may mislead the model. In a real life scenario, we'd have the \"hindsight\" values available in the historic data, just like we do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "159827b9-f633-435f-88e9-4a3effda324f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible sequences: 2186\n"
     ]
    }
   ],
   "source": [
    "n_sequences = (last_t - first_t) // 24 + 1 # Number of 16:00 rows followed by a sufficient input / output sequence\n",
    "print(\"Number of possible sequences: \" + f\"{n_sequences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "860bb74a-cf1f-405c-be9a-2d1871b8f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all sequences\n",
    "for t in range(first_t, last_t + 1, 24):\n",
    "\n",
    "    # Get input sequence\n",
    "    new_input = np.concatenate((\n",
    "        df_past.iloc[(t - input_length):t, 0].values.reshape(-1, 1),\n",
    "        df_future.iloc[(t - input_length):t, 1:].values\n",
    "    ), axis = 1)\n",
    "\n",
    "    # Get output sequence\n",
    "    new_output = df_future.iloc[t:(t + output_length), :].values\n",
    "\n",
    "    if t == first_t:\n",
    "\n",
    "        # Initialize arrays of sequences\n",
    "        input_sequences = np.array([new_input])\n",
    "        output_sequences = np.array([new_output])\n",
    "        \n",
    "    else:\n",
    "        # Concatenate to arrays of sequences\n",
    "        input_sequences = np.concatenate((input_sequences, [new_input]), axis = 0)\n",
    "        output_sequences = np.concatenate((output_sequences, [new_output]), axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253bf525-8f95-43af-9c5c-356248ae6cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2186, 72, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45ecfbe6-7de0-46bc-8435-5fc5ae5ecaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2186, 32, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "795a6b5b-eeae-4c9f-ab47-e371e6bd6fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39635.29"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be the last past target of the first input sequence. Row (first_t) in df_past.\n",
    "# Also the future target at row (first_t - 3) in df_future.\n",
    "input_sequences[0, -1, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "508fbeb8-c962-47ea-93d1-06e3f50ce548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82    40593.83\n",
       "83    40955.07\n",
       "84    39505.55\n",
       "85    39635.29\n",
       "86    39952.75\n",
       "87    39649.45\n",
       "88    40063.17\n",
       "Name: consumption_lag2, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_past.iloc[82:89, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7ad926d-4c91-4692-b3c6-913538b86341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40487.65"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be the first future target of the first input sequence. Row (first_t + 1) in df_future\n",
    "output_sequences[0, 0, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "451900a0-09c0-44fe-b143-722df28598d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82    39635.29\n",
       "83    39952.75\n",
       "84    39649.45\n",
       "85    40063.17\n",
       "86    40487.65\n",
       "87    39936.25\n",
       "88    38772.68\n",
       "Name: consumption_MWh, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_future.iloc[82:89, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3191d2d-983c-4bce-bbd3-6f1075fe8518",
   "metadata": {},
   "source": [
    "Sequencing seems successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a79ac-10d9-4de2-b973-99d6d60421cc",
   "metadata": {},
   "source": [
    "## Preprocessing, Torch datasets & dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3016ec43-cb1b-4f43-a5e8-b1650b7eebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices for train - val - test plit\n",
    "sixty_percent = int(input_sequences.shape[0] * 0.6)\n",
    "twenty_percent = int(input_sequences.shape[0] * 0.2)\n",
    "train_end = sixty_percent\n",
    "val_end = sixty_percent + twenty_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e763f7b-0356-4795-b1fe-63431e6bb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train - val - test split\n",
    "tr_input, tr_output = input_sequences[0:train_end], output_sequences[0:train_end] # Training data at validation step\n",
    "train_input, train_output = input_sequences[0:val_end], output_sequences[0:val_end] # Training data at testing step\n",
    "\n",
    "val_input, val_output = input_sequences[train_end:val_end], output_sequences[train_end:val_end]\n",
    "test_input, test_output = input_sequences[val_end:], output_sequences[val_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbb6dc-8bb4-488f-aa19-98c76dfe73d0",
   "metadata": {},
   "source": [
    "We have to scale the past consumption & trend values in the input sequences, and the future consumption & trend values in the output sequences, because they'll be the past values as the forecast horizon expands.\n",
    "\\\n",
    "We also need the ability to backtransform the network's final predictions accordingly. We need a class instead of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b699628a-d604-4623-8446-23eafd41770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scaling class for sequence data\n",
    "class sequence_scaler:\n",
    "\n",
    "    def __init__(self, feature_range = (-1, 1)):\n",
    "        self.lower = feature_range[0]\n",
    "        self.upper = feature_range[1]\n",
    "\n",
    "    def fit(self, input_seq, output_seq):\n",
    "\n",
    "        # Get number of features\n",
    "        self.num_features = input_seq.shape[2]\n",
    "        \n",
    "        # Extract & save minimum, maximum for each feature\n",
    "        feature_mini = []\n",
    "        feature_maxi = []\n",
    "        for feature in range(0, self.num_features):\n",
    "            min = np.min([\n",
    "                np.min(input_seq[:, :, feature]),\n",
    "                np.min(output_seq[:, :, feature])\n",
    "            ])\n",
    "            feature_mini.append(min)\n",
    "\n",
    "            max = np.max([\n",
    "                np.max(input_seq[:, :, feature]),\n",
    "                np.max(output_seq[:, :, feature])\n",
    "            ])\n",
    "            feature_maxi.append(max)\n",
    "\n",
    "        self.feature_mini = feature_mini\n",
    "        self.feature_maxi = feature_maxi\n",
    "\n",
    "    def transform(self, sequences):\n",
    "\n",
    "        # Initialize list of scaled features\n",
    "        scaled_features = []\n",
    "\n",
    "        # Scale each feature & append to list\n",
    "        for feature in range(0, self.num_features):\n",
    "            values = sequences[:, :, feature]\n",
    "            min = self.feature_mini[feature]\n",
    "            max = self.feature_maxi[feature]\n",
    "            std = (values - min) / (max - min)\n",
    "            scaled = std * (self.upper - self.lower) + self.lower\n",
    "            scaled_features.append(scaled)\n",
    "\n",
    "        # Stack over 3rd dimension & return\n",
    "        return np.stack(scaled_features, axis = 2)\n",
    "\n",
    "    def backtransform(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14cf3a58-b711-4157-abf7-0f066ec713b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale validation data\n",
    "scaler_val = sequence_scaler()\n",
    "_ = scaler_val.fit(tr_input, tr_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "409cf8e2-b964-4ae7-8e5c-f606bf2227f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.08952997e-01, -1.00000000e+00, -1.00000000e+00, -2.22044605e-16,\n",
       "        8.01937736e-01,  6.03875472e-01,  5.00000000e-01,  8.66025404e-01])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_val.transform(tr_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf377421-7c99-4210-87c4-dab14581571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Torch dataset class\n",
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    # Store preprocessed input & output sequences\n",
    "    def __init__(self, input_seq, output_seq): \n",
    "        self.input_seq = torch.tensor(input_seq, dtype = torch.float32) # Store inputs sequences\n",
    "        self.output_seq = torch.tensor(output_seq, dtype = torch.float32) # Store output sequences\n",
    "  \n",
    "    # Return data length  \n",
    "    def __len__(self):\n",
    "        return len(self.input_seq) \n",
    "  \n",
    "    # Return a pair of input & output sequences\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_seq[idx], self.output_seq[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c517f-376f-43e2-8839-16e9b261e80f",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da1985-55fe-4b63-bf5a-fed283a299e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model class\n",
    "class StatefulQuantileLSTM(L.LightningModule):\n",
    "\n",
    "    # Initialize model\n",
    "    def __init__(self, hyperparams_dict):\n",
    "        \n",
    "         # Delegate function to parent class\n",
    "        super().__init__() \n",
    "        \n",
    "        # Save external hyperparameters so they are available when loading saved models\n",
    "        self.save_hyperparameters(logger = False) \n",
    "\n",
    "        # Define hyperparameters\n",
    "        self.input_length = hyperparams_dict[\"input_length\"] # Length of input sequence. Necessary?\n",
    "        self.output_length = hyperparams_dict[\"output_length\"] # Length of output sequence\n",
    "        self.input_size = hyperparams_dict[\"input_size\"] # Number of features (network inputs)\n",
    "        self.horizon = hyperparams_dict[\"horizon\"] # Start of the forecast horizon relevant for loss computing\n",
    "        self.quantiles = hyperparams_dict[\"quantiles\"] # Provide as list of floats: [0.025, 0.5, 0.975]\n",
    "        self.learning_rate = hyperparams_dict[\"learning_rate\"]\n",
    "        self.lr_decay = hyperparams_dict[\"lr_decay\"]\n",
    "        self.num_layers = hyperparams_dict[\"num_layers\"] # Number of layers in the LSTM block\n",
    "        self.hidden_size = hyperparams_dict[\"hidden_size\"] # Number of units in each LSTM block = LSTM block output size\n",
    "        self.dropout_rate = hyperparams_dict[\"dropout_rate\"]\n",
    "\n",
    "        # Define architecture\n",
    "        \n",
    "        # LSTM input: input, (prev_hidden_state, prev_cell_state)\n",
    "        # Shapes: (N, input_length, input_size), ((num_layers, N, hidden_size), (num_layers, N, hidden_size))\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = self.input_size,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = True\n",
    "        )\n",
    "        # LSTM output: output, (last_hidden_states, last_cell_states)\n",
    "        # Shapes: (N, input_length, hidden_size), ((num_layers, N, hidden_size), (num_layers, N, hidden_size))\n",
    "        # The tuple of hidden states & cell states have the last hidden & cell states for each LSTM layer.\n",
    "\n",
    "        # Output layer input: LSTM output, shape (N, input_length, hidden_size)\n",
    "        self.output_layer = torch.nn.Linear(\n",
    "            in_features = self.hidden_size,\n",
    "            out_features = 1\n",
    "        )\n",
    "        # Output layer output: Scalar prediction, shape (N, 1)\n",
    "\n",
    "        # Loss function: Quantile loss\n",
    "        self.loss = QuantileLoss(quantiles = self.quantiles)\n",
    "\n",
    "    # Define forward propagation\n",
    "    def forward(self, input_chunk, prev_states = None): # Pass prev_states as (prev_hidden_states, prev_cell_states)\n",
    "\n",
    "        # Pass inputs through LSTMs\n",
    "        # If prev_states is not passed, they are automatically initialized as zeroes\n",
    "        if prev_states == None:\n",
    "            lstm_output, (last_hidden_states, last_cell_states) = self.lstm(input_chunk)\n",
    "        else: \n",
    "            lstm_output, (last_hidden_states, last_cell_states) = self.lstm(input_chunk, prev_states)\n",
    "\n",
    "        # Pass LSTM output through output layer\n",
    "        preds = self.output_layer(lstm_output)\n",
    "\n",
    "        return last_hidden_states, last_cell_states, preds\n",
    "\n",
    "    # Define training step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # Initialize variables to record horizon, hidden & cell states, predictions\n",
    "        h = 0\n",
    "        prev_hiddens = []\n",
    "        prev_cells = []\n",
    "        batch_preds = []\n",
    "\n",
    "        # Get inputs & outputs for first forecast step\n",
    "        input_sequences, output_sequences = batch\n",
    "        input_seq = input_sequences # Inputs of the forecast step 0. (N, input_length, input_size) \n",
    "        output_seq = output_sequences[:, 0, :] # Target & future covars of forecast step 0. Needed for later forecast steps. (N, 1, input_size)\n",
    "\n",
    "        # Perform training & recording for first forecast step\n",
    "        # If a hidden & cell state is retained from the previous batch, use it. This will be the case for all batches except the first in an epoch.\n",
    "        if self._last_hiddens_train == None:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(input_seq)\n",
    "        else:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (self._last_hiddens_train, self._last_cells_train)\n",
    "            )\n",
    "\n",
    "        prev_hiddens.append(last_hidden_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        prev_cells.append(last_cell_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        batch_preds.append(preds) # 1-dimensional list. Each element has shape (N, 1)\n",
    "        h += 1\n",
    "\n",
    "        # Perform training & recording for remaining forecast steps\n",
    "        while h < (self.output_length - 1):\n",
    "\n",
    "            # Get inputs & outputs for forecast step h: \n",
    "            input_seq = torch.cat((\n",
    "                input_seq[:, 1:, :], # Inputs of the previous forecast step, with the first row dropped. (N, input_length - 1, input_size)\n",
    "                output_seq, # Target & future covars of previous forecast step, the last row of the new input. (N, 1, input_size)\n",
    "            ), dims = 1)\n",
    "            \n",
    "            output_seq = output_sequences[:, h, :] # Target & covars. of forecast step h. Needed for later forecast steps. (N, 1, input_size)\n",
    "\n",
    "            # Perform training & recording for forecast step h:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (prev_hiddens[h-1], prev_cells[h-1])\n",
    "            )\n",
    "            prev_hiddens.append(last_hidden_states)\n",
    "            prev_cells.append(last_cell_states)\n",
    "            batch_preds.append(preds)\n",
    "            h += 1\n",
    "\n",
    "        # Calculate loss for forecast steps starting from horizon\n",
    "        preds_horizon = batch_preds[self.horizon:] # List length (output_length - horizon). Each elememt has shape (N, 1).\n",
    "        preds_horizon = torch.cat(preds_horizon, dim = 1) # Shape (N, output_length - horizon) # RESHAPE???\n",
    "\n",
    "        loss = self.loss.loss(\n",
    "            preds_horizon, \n",
    "            output_sequences[:, self.horizon: , 0] # Target values from horizon to end of sequence. Shape(N, output_length - horizon, 1)\n",
    "        )\n",
    "\n",
    "        # Log the training loss\n",
    "        self.log(\"train_loss\", loss, on_step = True, on_epoch = True, prog_bar = True, logger = True)\n",
    "\n",
    "        # Update last hidden & cell states from training (for within-epoch use)\n",
    "        self._last_hiddens_train = prev_hiddens[-1]\n",
    "        self._last_cells_train = prev_cells[-1]\n",
    "\n",
    "        # Update final hidden & cell states from training (for inference)\n",
    "        self._final_hiddens_train = prev_hiddens[-1]\n",
    "        self._final_cells_train = prev_cells[-1]\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    # When a training epoch ends, flush the last hidden & cell states.\n",
    "    # Final hidden & cell states remain for inference.\n",
    "    def on_train_epoch_end(self):\n",
    "        self._last_hiddens_train = None\n",
    "        self._last_cells_train = None\n",
    "\n",
    "    # Method to flush the final hidden & cell states left from training, if desired\n",
    "    def reset_context(self):\n",
    "        self._final_hiddens_train = None\n",
    "        self._final_cells_train = None\n",
    "\n",
    "    # Define validation_step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        # Initialize variables to record horizon, hidden & cell states, predictions\n",
    "        h = 0\n",
    "        prev_hiddens = []\n",
    "        prev_cells = []\n",
    "        batch_preds = []\n",
    "\n",
    "        # Get inputs & outputs for first forecast step\n",
    "        input_sequences, output_sequences = batch\n",
    "        input_seq = input_sequences # Inputs of the forecast step 0. (N, input_length, input_size) \n",
    "        output_seq = output_sequences[:, 0, :] # Target & future covars of forecast step 0. Needed for later forecast steps. (N, 1, input_size)\n",
    "\n",
    "        # Perform validation & recording for first forecast step\n",
    "        # If a hidden & cell state is retained from training, use it.\n",
    "        if self._final_hiddens_train == None:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(input_seq)\n",
    "        else:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (self._final_hiddens_train, self._final_cells_train)\n",
    "            )\n",
    "\n",
    "        prev_hiddens.append(last_hidden_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        prev_cells.append(last_cell_states) # 1-dimensional list. Each element has shape (num_layers, N, hidden_size)\n",
    "        batch_preds.append(preds) # 1-dimensional list. Each element has shape (N, 1)\n",
    "        h += 1\n",
    "\n",
    "        # Perform training & recording for remaining forecast steps\n",
    "        while h < (self.output_length - 1):\n",
    "\n",
    "            # Get inputs & outputs for forecast step h: \n",
    "            input_seq = torch.cat((\n",
    "                input_seq[:, 1:, :], # Inputs of the previous forecast step, with the first row dropped. (N, input_length - 1, input_size)\n",
    "                output_seq, # Target & future covars of previous forecast step, the last row of the new input. (N, 1, input_size)\n",
    "            ), dims = 1)\n",
    "            \n",
    "            output_seq = output_sequences[:, h, :] # Target & covars. of forecast step h. Needed for later forecast steps. (N, 1, input_size)\n",
    "\n",
    "            # Perform training & recording for forecast step h:\n",
    "            last_hidden_states, last_cell_states, preds = self.forward(\n",
    "                input_seq, \n",
    "                prev_states = (prev_hiddens[h-1], prev_cells[h-1])\n",
    "            )\n",
    "            prev_hiddens.append(last_hidden_states)\n",
    "            prev_cells.append(last_cell_states)\n",
    "            batch_preds.append(preds)\n",
    "            h += 1\n",
    "\n",
    "        # Calculate loss for forecast steps starting from horizon\n",
    "        preds_horizon = batch_preds[self.horizon:] # List length (output_length - horizon). Each elememt has shape (N, 1).\n",
    "        preds_horizon = torch.cat(preds_horizon, dim = 1) # Shape (N, output_length - horizon) # RESHAPE???\n",
    "\n",
    "        loss = self.loss.loss(\n",
    "            preds_horizon, \n",
    "            output_sequences[:, self.horizon: , 0] # Target values from horizon to end of sequence. Shape(N, output_length - horizon, 1)\n",
    "        )\n",
    "\n",
    "        # Log the val. loss\n",
    "        self.log(\"val_loss\", loss, on_step = True, on_epoch = True, prog_bar = True, logger = True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Define prediction_step\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "\n",
    "        # Stack the prediction at h = 0 (N, output_length, 1) with the future covars (N, output_length, 1)\n",
    "\n",
    "       \n",
    "        \n",
    "\n",
    "    # Define optimizer & learning rate scheduler\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # Adam optimizer\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "        \n",
    "        # Exponential LR scheduler\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "          optimizer, gamma = self.lr_decay) \n",
    "        \n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "          \"scheduler\": lr_scheduler\n",
    "          }\n",
    "        }\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
